[TOC]

机器学习的课题就是将决定函数的参数值的工作交由计算机自动进行。 学习是确定合适的参数的过程，而人要做的是思考感知机的构造（模型），并把训练数据交给计算机。

机器学习——让机器具有找函数的能力，知道输入和期望的输出，实现过程依赖机器学习，例如语音识别（输入——音频，输出——文字，让机器实现转换过程的函数）
# 机器学习分类（根据要找的函数类型不同）
regression（回归）：函数输出是数值
classification（分类）：给出选项（类别），函数输出正确选项
structured learning：创造（输出）有结构的东西（机器画图/写文章等）
[# 人工智能导论(6)——机器学习(Machine Learning)](https://blog.csdn.net/hustlei/article/details/121803226)
![输入图片说明](/imgs/2024-08-08/xRDdC8Rawaz6nSuE.png)


# 找函数的过程
### 1.写出带有未知参数的函数
猜测函数的数学式，做出猜测需要domain knowledge（领域知识）
![输入图片说明](/imgs/2024-07-23/Zjv3uPsw4wDUmK5d.png)
模型(model)即带有未知参数的函数
feature（特征）是机器学习模型的输入变量

个人认为，设计model的时候要先根据knowledge找出要考虑的因素，然后对这些因素的training data画图（描点），然后思考要带什么model，如果结果不理想要考虑其它因素或者更换model
在宝可梦的例子中，一开始只是考虑进化前和进化后的cp值，尝试了一次到五次的式子
![输入图片说明](/imgs/2024-07-25/RALbHKtb38t98Fk2.png)
后面又考虑了宝可梦的种类，不同种类的宝可梦分开代入不同的式子，用的是线性方程
![输入图片说明](/imgs/2024-07-25/qMcC7PB2wse9cbtk.png)
之后又考虑了hp、weight、height的影响，用的是二次式（所有能想到的因素全部算进去）
![输入图片说明](/imgs/2024-07-25/xkT01licO1gDlv9i.png)
但是实际上这种方法overfitting了，所有要采取一种方式处理这个问题，也就是regularization（正则化）
#### regularization（正则化）
[# 正则化](https://blog.csdn.net/weixin_41960890/article/details/104891561?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172187472816800211528758%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172187472816800211528758&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-104891561-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=regularization&spm=1018.2226.3001.4187)
正则化就是说给参数加上一些限制，通过这种规则去规范他们再接下来的循环迭代中，不要自我膨胀，防止模型过拟合
![输入图片说明](/imgs/2024-07-25/kUqDljq7zuFTGs4B.png)
![输入图片说明](/imgs/2024-07-25/HMSWO3DUrJBUOnYX.png)
在做regularization时不考虑bias项，bias值不影响function的平滑程度
### 2.基于训练数据定义loss（损失）
Loss是关于未知参数的函数 L（b，w），用于评价得到的参数值的好坏（函数自己定义），一般loss越小越好（loss可以是负数）
label（标签）：所预测的东西实际是什么（可理解为结论），如线性回归中的 y 变量，如分类问题中图片中是猫是狗（或图片中狗的种类）、房子未来的价格、音频中的单词等输出，都属于Label。

![输入图片说明](/imgs/2024-07-23/oNGuoPDEIt9HFshc.png)

error surface:参数取不同值计算loss得到的等高线图
![输入图片说明](/imgs/2024-07-23/dWNKS1s2JXfY2qjd.png)

分类问题常使用交叉熵作为loss函数 [# 理解交叉熵（Cross Entropy）](https://blog.csdn.net/aimengh/article/details/129145593?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172180418416800225555255%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172180418416800225555255&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-129145593-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=cross%20entropy&spm=1018.2226.3001.4187)
### 3.最佳化
找到使Loss最小化的参数
#### Gradient Descent（梯度下降法）
方法之一：Gradient Descent（梯度下降法）
[梯度下降法](https://blog.csdn.net/qq_38784098/article/details/120934613)
1.为了便于理解，先假设只有一个未知参数（假设另一个已知），比如对于y=wx+b，先假设b已知，w未知
2.然后随机选取一个w的值（初始点w0），计算在w0处L关于w的导数，如果为负值就增加w，如果为正就减小w（找极小值）
3.w的增减幅度取决于导数值的大小和学习速率（人为设定的）
学习速率是一种（hyperparameter）超参数[超参数（Hyperparameter） - HuZihu - 博客园 (cnblogs.com)](https://www.cnblogs.com/HuZihu/p/10641972.html)
![输入图片说明](/imgs/2024-07-23/ipSxiTHJYsCwLSZw.png)

Gradient Descent可能出现local minima的问题（loss局部最小但并非总体最小）

推广到有两个参数的情况：求偏导

![输入图片说明](/imgs/2024-07-23/Jt5SofaWA2gQDdqD.png)
![输入图片说明](/imgs/2024-07-23/Ty81Z2Qi1mHwkgZ8.png)

以上的为linear model，对于一些复杂数据的拟合效果可能并不好，因此我们需要更复杂的模型来拟合

## 其它模型
### sigmoid
用一组分段折线加常数来拟合数据
![输入图片说明](/imgs/2024-07-23/bMHaOaTRA8YRG6XZ.png)
用曲线逼近折线
![输入图片说明](/imgs/2024-07-23/fQLyA7CjXiEwCNBF.png)
当x很大时，曲线会趋近于c；当x很小时，曲线会趋近于0，可以很好地逼近折线
蓝色的function（折线）被称为hard sigmoid


调整b,w,c参数可以使sigmoid function逼近hard sigmoid
改变w可以改变斜率，改变b可以改变左右位置，改变c可以改变高度
![输入图片说明](/imgs/2024-07-23/FK46uuRksKbhqfto.png)

最终拟合
![输入图片说明](/imgs/2024-07-23/SGh1fpWqLAEiu6E8.png)
![输入图片说明](/imgs/2024-07-23/mlJkwMhIRH0zKiRL.png)
![输入图片说明](/imgs/2024-07-23/y6wbjBiPn2ReV4Lo.png)

 得到loss
![输入图片说明](/imgs/2024-07-23/9JCmk40VJ6Eyb2MH.png)
θ代表的是所有参数
![输入图片说明](/imgs/2024-07-23/yxnxgePrj2QczTWn.png)

最佳化
![输入图片说明](/imgs/2024-07-23/41YKQstG0buUMi1X.png)
**gradient——梯度**

![输入图片说明](/imgs/2024-07-23/r9uotHLTHhfYWsBe.png)
![输入图片说明](/imgs/2024-07-23/8tznNBsbqXJP8TA4.png)
实际上，并不是拿L算gradient，而是拿多个batch（批次）的L1,L2......来计算
区分epoch和update：每次参数更新一次叫做update，把所有batch看一遍叫epoch

> epoch：训练时，所有训练数据集都训练过一次。
> batch_size：在训练集中选择一组样本用来更新权值。1个batch包含的样本的数目，通常设为2的n次幂，常用的包括64,128,256。 
> 网络较小时选用256，较大时选用64。

sigmoid可能会造成[gradient vanish](https://blog.csdn.net/qq_29893385/article/details/81214737?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172242601916800172526384%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172242601916800172526384&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-81214737-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=gradient%20vanish&spm=1018.2226.3001.4187)的问题，因此出现了ReLU

### ReLU
![输入图片说明](/imgs/2024-07-23/PN4EWyGRLRqhcuie.png)
2个ReLU可以组合成一个sigmoid
![输入图片说明](/imgs/2024-07-23/PYoDSKONlkJsB5tK.png)
因此
![输入图片说明](/imgs/2024-07-23/P8M0K8R80oO1dnx7.png)
ReLU更好
# 机器学习的原理
对于分类宝可梦和数码宝贝
先把图像转换为线条，在通过计算线条所占的pixel，来估计图像的复杂程度，从而分类
![输入图片说明](/imgs/2024-07-27/iR3lDAAfQ1BgU0Cm.png)
threshold——门槛
H是所有h所有可能的数值，|H|选择性多，也就是模型复杂程度大

![输入图片说明](/imgs/2024-07-28/qh21Rx5MOs7ziSDu.png)

![输入图片说明](/imgs/2024-07-28/FXWtnsuS5vs4CSd4.png)
![输入图片说明](/imgs/2024-07-28/W6pj1IAYUTDZnl2Q.png)

理想（用所有存在的数据得到的h）和现实中（用来训练的数据得到的h）之间的差距部分取决于sample的资料
好的资料（更能代表所有情况的取样）可以让理想和现实非常接近
![输入图片说明](/imgs/2024-07-28/rUdzxl9mfuad8zNZ.png)
因此得到我们的取样目标：
![输入图片说明](/imgs/2024-07-28/N499eQ6qCNQpgR8x.png)

![输入图片说明](/imgs/2024-07-28/L685QMgRHIo47MxJ.png)
接下来对于机器学习原理的讨论非常一般化！
![输入图片说明](/imgs/2024-07-28/gCk935yukYMhJHjX.png)
![输入图片说明](/imgs/2024-07-28/p48W61zQfu3VPc45.png)
概率总和可能会超过1，这时候这个理论就会失效
![输入图片说明](/imgs/2024-07-28/xmgp2dmoK6PXQP19.png)

![输入图片说明](/imgs/2024-07-28/lPjGoS9PGkjeLI8u.png)
实际上将数值代入不等式计算得到的数值往往是大于1的，因此这个式子大部分只是用于理论分析，不会在实际运算中用到
![输入图片说明](/imgs/2024-07-28/hbGDvsrqJ3zoLvXW.png)
![输入图片说明](/imgs/2024-07-28/bKS6J7g3ADGSFgNC.png)
[VC Dimension](https://blog.csdn.net/qq_43391414/article/details/111692672?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172214660116800175779618%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172214660116800175779618&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-5-111692672-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=VC%20Dimension&spm=1018.2226.3001.4187)：全称是Vapnik-Chervonenkis dimension,用来衡量一个模型的复杂度
![输入图片说明](/imgs/2024-07-28/t9FU2rS24NA7XRdT.png)
# 深度学习
![输入图片说明](/imgs/2024-07-23/UYoPuxiECByWk5kr.png)
W'等参数与之前的不同，增加了更多未知的参数
![输入图片说明](/imgs/2024-07-23/TghVCVy71CjzJshW.png)

## overfitting
在训练资料上Loss变小但是在没看过的资料上没有变好的现象
在training data上，越复杂的model会产生越小的error，但是在testing data上，越复杂的model并不一定就可以带来越好的结果，因此Model不是越复杂越好，我们要选择合适的model
overfitting要减少参数


实际上深度学习可以理解为在机器学习的第一步中，function就是neural network
![输入图片说明](/imgs/2024-07-24/8V4vVRujQt7bhV5P.png)
所以关键在于对neural network的理解


## neural network
![输入图片说明](/imgs/2024-07-24/JSVhsTzVI5GMUy3P.png)

输入的数据叫input layer，输出的数据叫output layer，其余的叫hidden layer
![输入图片说明](/imgs/2024-07-24/N52JiDy0vlP0nikV.png)
deep=many hidden layers

![输入图片说明](/imgs/2024-07-24/mzo8h2dbDAlTQERY.png)
hidden layers可以看作是feature extractor（特征提取），代替了人工feature engineering的工作[机器学习之特征工程](https://blog.csdn.net/qq_52297180/article/details/128514227?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172179291916800172552368%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172179291916800172552368&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-128514227-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=feature%20engineering&spm=1018.2226.3001.4187)
对于多类分类问题，最后一个layer(output layer)会加上softmax      [softmax回归](https://blog.csdn.net/qq_38473254/article/details/131718450?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172178414216800175799400%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172178414216800175799400&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-2-131718450-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=softmax&spm=1018.2226.3001.4187)
softmax是对最大值做强化
![输入图片说明](/imgs/2024-07-24/5KKWWRCwlf3mpbTq.png)
知道input和output的向量维数，但是中间的layer数和每层layer中的neuron数要自己设计（凭借直觉和经验）
### fully connect feedforward network
已知结构（神经元连接方式），可以得到一组方程（参数不同）
 fully connect feedforward network的连接方式就是层和层之间所有的neuron两两之间都有连接（fully connect），传递方向由后往前传（feedforward）
![输入图片说明](/imgs/2024-07-24/4L4zJMqAM7Qzmz3m.png)
## network的运作——matrix operation
![输入图片说明](/imgs/2024-07-24/cxn643uPnNaIxUvl.png)
好处是可以用GPU加速矩阵运算
## Back propagation（反向传播）
使用gradient descent方法训练neural network的算法[# 深度学习——反向传播（Backpropagation）](https://blog.csdn.net/johnny_love_1968/article/details/117598649?ops_request_misc=&request_id=&biz_id=102&utm_term=backpropagation&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-2-117598649.142%5Ev100%5Epc_search_result_base2&spm=1018.2226.3001.4187)
因为DL有多层和非常多个神经元，参数非常多，因此需要更高效的方法去计算梯度
回顾一下：θ代表所有的参数，loss是与θ有关的函数，梯度是L(θ)关于每一项参数偏导的向量
![输入图片说明](/imgs/2024-07-24/5FgXjj7lsu3yv9tY.png)
![输入图片说明](/imgs/2024-07-24/amMpuo2b62PXUlmE.png)
接下来先考虑对于某一个neuron
![输入图片说明](/imgs/2024-07-24/QeVFXeny3uggmnZH.png)
forward pass非常容易计算
![输入图片说明](/imgs/2024-07-24/OXA6o7GWG5JrtItD.png)
计算backward pass

把backward pass拆开
![输入图片说明](/imgs/2024-07-24/jYyEyVPN8nQvuF7h.png)
已知a=sigmoid(z)，所以a对z的偏导可以容易地求出
![输入图片说明](/imgs/2024-07-24/GG9JqsbSSaSmXhH8.png)

求C对a的偏导
![输入图片说明](/imgs/2024-07-24/hJApMAbntJhvNjl4.png)
![输入图片说明](/imgs/2024-07-24/W3e5SCSswsRRSxVM.png)
计算![输入图片说明](/imgs/2024-07-24/DVXrVut7qkp89lUU.png)等项
第一种情况：y1与y2在都在输出层
![输入图片说明](/imgs/2024-07-24/PgenCqCzqeOnDQk8.png)
第二种情况：y1,y2不在输出层的情况
![输入图片说明](/imgs/2024-07-24/jZvllBJgnYCoVcoY.png)
因此从输出层开始算，从后往前算
![输入图片说明](/imgs/2024-07-24/5eny6roUe8gMsZFU.png)
相当于建立了新的neural network

总结
![输入图片说明](/imgs/2024-07-24/DethFHTRFevn71bN.png)
## 分类
如果在分类时采用regression的方法，regression定义方向好坏的方式对分类来说是不适用的。
![输入图片说明](/imgs/2024-07-25/LpqsuDoGJ83vHmED.png)
在如图的二分类中，把点分为大于0和小于0的，显然绿色的线是更好的function，但是对于regression来讲，为了降低error，它认为紫色的线是更好的function
### 理想的做法
![输入图片说明](/imgs/2024-07-25/EEQxwyyjGDVNzNPO.png)
### generative model之几率模型
![输入图片说明](/imgs/2024-07-25/Fd1rpmTCR62JODwD.png)
[# 生成模型(Generative Model)](https://blog.csdn.net/huang1024rui/article/details/118513236?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172187854316800227448551%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172187854316800227448551&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-118513236-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=generative%20model&spm=1018.2226.3001.4187)
假如现在有两个类C1和C2，现在输入一个对象x，要计算从C1类中挑出一个对象，挑到A的概率是多少（这个A可能没有在training data中出现过，但并不代表它出现的概率是0）也就是要计算P(x|C1)
![输入图片说明](/imgs/2024-07-25/zhcJyMcedhhMYl1d.png)
Gaussian distribution（高斯分布），即正态分布    [# 深度学习中的高斯分布](https://blog.csdn.net/lsb2002/article/details/134935811?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172189049816800185813158%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172189049816800185813158&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-134935811-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=gaussian%20distribution&spm=1018.2226.3001.4187)
均值向量和协方差矩阵决定了高斯分布的形状  [# 均值向量和协方差矩阵](https://blog.csdn.net/qq_44154915/article/details/134454966?ops_request_misc=&request_id=&biz_id=102&utm_term=%CE%BC%E5%90%91%E9%87%8F%E5%92%8Ccovariance%20matrix&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-134454966.142%5Ev100%5Epc_search_result_base2&spm=1018.2226.3001.4187)
![输入图片说明](/imgs/2024-07-25/ecdMpSMaJRXF83Uk.png)
要根据已有的training data找出Gaussian distribution，即可算出P(x|C1)，所以接下来要算出μ向量和Σ矩阵（均值向量和协方差矩阵）
#### maximum likelihood（极大似然估计）
![输入图片说明](/imgs/2024-07-25/xroEVSoQP72jxLNS.png)
穷举所有的μ向量和Σ矩阵，找出sample出所有training data的概率最大的Gaussian，对应的μ向量和Σ矩阵即要找的μ向量和Σ矩阵
![输入图片说明](/imgs/2024-07-25/SNXv8FHjGUx8XSEp.png)

![输入图片说明](/imgs/2024-07-25/eJwXqsNn95IIgs5r.png)
由于老师发现用七个维度的x也没办法很好地解决这个问题（正确率只有50%左右），于是他决定减少参数

减少参数的办法就是让两个类共用一个covariance matrix（Σ），事实上，更多的模型其实采用的是这种方法
![输入图片说明](/imgs/2024-07-25/XQ3ebfB2uWXAbqp9.png)
![输入图片说明](/imgs/2024-07-25/tXS5rxHqOXSA97lr.png)
#### 总结
![输入图片说明](/imgs/2024-07-25/A5Lw2HdewnSGfshv.png)
再看看其他分布方式吧
如果是二项分布（只分两类），那么就可以采用[# 伯努利分布（Bernoulli distribution）](https://blog.csdn.net/qq_42983182/article/details/138078493?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172189697716800222877054%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172189697716800222877054&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-138078493-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=bernoulli%E5%88%86%E5%B8%83&spm=1018.2226.3001.4187)
如果特征之间没有关系的话，可以使用[# 贝叶斯分类器(Naive Bayes Classifier)](https://blog.csdn.net/qq_34758157/article/details/126657168?ops_request_misc=&request_id=&biz_id=102&utm_term=naive%20bayes%20classifier&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-126657168.142%5Ev100%5Epc_search_result_base2&spm=1018.2226.3001.4187)

#### posterior probability（后验概率）
后验概率：事件发生后求的反向条件概率；或者说，基于先验概率求得的反向条件概率。概率形式与条件概率相同。
回顾一下，条件概率 P(B|A)指的是已知事件A发生的条件下，事件B发生的概率为条件概率，计算公式：P(B|A)=P(AB)/P(A)
贝叶斯公式：
![输入图片说明](/imgs/2024-07-25/6gYhwbpZIxquXrKp.png)

![输入图片说明](/imgs/2024-07-25/IccLLR7r5j2Lppcy.png)
![输入图片说明](/imgs/2024-07-25/Yl4N9ZQ43JI0trOd.png)
经过一串非常复杂的运算后，得到
![输入图片说明](/imgs/2024-07-25/Eftbr2jTQYYwpw16.png)
通过share同一个Σmatrix，我们得到了一个类似于线性回归的model
所以为了直接找出w和b，运用了Logistic Regression
## Logistic Regression（逻辑回归）
[# 逻辑回归（Logistic Regression)详解](https://blog.csdn.net/weixin_60737527/article/details/124141293?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172189966716800182144928%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172189966716800182144928&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-124141293-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=Logistic%20Regression&spm=1018.2226.3001.4187)
![输入图片说明](/imgs/2024-07-25/vSV4xrDmnT0CMZNQ.png)
![输入图片说明](/imgs/2024-07-25/b6kebp34iQMgJ5yv.png)
这个model就叫做logistic regression
![输入图片说明](/imgs/2024-07-25/xCUyjPvApSFfTI0o.png)
PS:要知道argmin和argmax的意思，就是使函数取得最小值的自变量的值
![输入图片说明](/imgs/2024-07-25/8QF14LAFuyhxSis3.png)
继续正题，对之前的L(w,b)作变化，
![输入图片说明](/imgs/2024-07-25/P8xOzKfjetwcPAum.png)
将y hat代入然后统一式子
取ln是因为可以把相乘化成相加，最后的结果是一样的（因为求的是自变量的值）
![输入图片说明](/imgs/2024-07-25/cioTKAIZ6jmwv2K9.png)
![输入图片说明](/imgs/2024-07-25/5TDLdMIHkYhXnWU4.png)
PS:cross entropy（交叉熵）是用来衡量两个概率分布之间的差异性的一种方法[# 交叉熵简介](https://blog.csdn.net/m0_57236802/article/details/129554878?ops_request_misc=&request_id=&biz_id=102&utm_term=%E4%BA%A4%E5%8F%89%E7%86%B5&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-129554878.nonecase&spm=1018.2226.3001.4187)
![输入图片说明](/imgs/2024-07-25/mTu9NpvRTnqv4FJA.png)
![输入图片说明](/imgs/2024-07-25/yOIS3O8lFxkMaUj6.png)
以上的步骤都是为了计算梯度，之后就可以update了
![输入图片说明](/imgs/2024-07-25/n3mJabVqDARi0bgd.png)

### 对比逻辑回归和线性回归的三步骤
注意逻辑回归的y hat是0或者1，线性回归的y hat是任何真实的数字
![输入图片说明](/imgs/2024-07-25/lgTn6TU0CsgPdtxA.png)
![输入图片说明](/imgs/2024-07-25/Rd6oRaPLsSVROEjv.png)

这里有一个问题，就是对于步骤二，为什么在逻辑回归中不像线性回归那样使用square error（也就是上上张图中提出的问题）

PS:回顾一下线性回归的步骤二
![输入图片说明](/imgs/2024-07-23/oNGuoPDEIt9HFshc.png)

如果在逻辑回归中使用square error
![输入图片说明](/imgs/2024-07-25/99stqz3yrOvlfJ5N.png)
![输入图片说明](/imgs/2024-07-25/OQ7DeEIErjbj5N3D.png)
![输入图片说明](/imgs/2024-07-25/RjTGe83mUDo2QkjH.png)
cross entropy可以做到当距离最优值很远的时候，微分值大，update就多；但是square error不行
### 逻辑回归的限制
![输入图片说明](/imgs/2024-07-25/HUCYi6fnTmkjSuNt.png)
![输入图片说明](/imgs/2024-07-25/pFcaQ3dgqtgn1b9E.png)
逻辑回归两个类之间的boundary是一条直线，无法将红蓝四个点完全分类
solution:feature transformation
![输入图片说明](/imgs/2024-07-25/0AM45F0Tsl9YiW3H.png)
于是我们希望可以用机器来找到这个transformation
于是我们采用级联逻辑回归的方法
![输入图片说明](/imgs/2024-07-25/4DOHRLkEEZX9chky.png)
![输入图片说明](/imgs/2024-07-25/BNBbH9gpj3Z7OS3W.png)
## 生成模型（Generative）VS 判别模型（Discriminative）
[# 生成模型（Generative）和判别模型（Discriminative）](https://blog.csdn.net/weixin_39910711/article/details/89483662)
![输入图片说明](/imgs/2024-07-25/aS44gGSxKN5oF2j2.png)

因为对两种模型做出了不同的假设，所以得到了不同的参数，得到了不同的function
discriminative没有做出任何假设而直接求w和b
而Generative中，对probability distribution是有做假设的，我们会假设它是Gaussian distribution、Bernoulli distribution、Naive Bayes Classifier等等

Discriminative model的表现常常会比Generative model更好，因为Generative model会“脑补”，也就是对于在training data中没有的特征Generative model也会“现象”出来这个特征存在（有概率出现）

但是Generative model也有它的优势。
Discriminative model因为没有做假设，完全是看data训练，因此需要大量的data；而Generative model受data的影响比较小，在data少量的情况下有时会优于Discriminative model。
同时，Discriminative model因为假设，受到有问题的data、label的影响更小
除此之外，先验概率和类相关概率可以从不同的来源进行估计

![输入图片说明](/imgs/2024-07-25/F9UCry00uQW5h4qH.png)
## 多类分类
用[softmax函数](https://blog.csdn.net/weixin_53765658/article/details/136229995?ops_request_misc=&request_id=&biz_id=102&utm_term=softmax%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-136229995.142%5Ev100%5Epc_search_result_base2&spm=1018.2226.3001.4187)处理z（z可以是任何数）
![输入图片说明](/imgs/2024-07-25/NYxVPyFMOQfxF2TB.png)
得到的结果全是正的并且所有结果的和为1
softmax是对最大值做强化，因为取e的指数可以强化数之间的差，可以强化大的值


交叉熵计算方式
![输入图片说明](/imgs/2024-07-25/htoF9wxlIpWmgT5N.png)
![输入图片说明](/imgs/2024-07-25/5wdoizQaca2o1mHu.png)

# 任务攻略
![输入图片说明](/imgs/2024-07-26/q85z9zGLccTpFLlE.png)
## loss on training data-->large
### model bias
model bias是指model过于简单而导致 未知参数取了所有值得到的function set中没有能使loss很小的function
解决方法：增加更多feature（增加x的维度）、设一个更大的model（更大的model可以得到更多function set）、使用DL增加model的弹性
![输入图片说明](/imgs/2024-07-26/qy4DHygl3Gq2GMzC.png)
### optimization issue
使用gradient descent方法可能会有local minima的问题，导致无法找到全局最优解
![输入图片说明](/imgs/2024-07-26/5gwkFhWohBY1ZFCt.png)
那么如何判断到底是这两种问题中的哪一种呢？
### model bias VS optimization issue
可以通过比较不同模型来得知现在的Model够不够大（是否是model bias的问题）
![输入图片说明](/imgs/2024-07-26/lpUtbuaqQvoGw9OI.png)
判断问题：如果是overfitting，那么56层在训练数据上就应该做的比20层的更好；如果是model bias的话，那么56层在所有数据上都应该做的比20层的更好
如果在训练数据上，更深的网络没有比浅的表现的更好（loss更小），就应该是optimization的问题

![输入图片说明](/imgs/2024-07-26/04lbricRyc5NT9GC.png)
## loss on training data-->small
### loss on testing data-->large
#### overfitting
![输入图片说明](/imgs/2024-07-26/ezsYU4xPohQPBuwS.png)
非常flexible的model就可能会出现overfitting的问题

solution：1.增加训练资料
2.[数据增强(Data Augmentation)](https://blog.csdn.net/weixin_44211968/article/details/120995096?ops_request_misc=&request_id=&biz_id=102&utm_term=data%20augmentation&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-120995096.nonecase&spm=1018.2226.3001.4187)
注意在数据增强时，要确保不增加不相关的数据。要根据自己对资料的特性、对问题的理解来选择合适的方式增加资料（例如影像处理时，在现实生活中可能不会出现某些影像的倒置，比如一碗汤，因此在做数据增强时，不要对这种图片进行倒置处理）
3.限制模型（比如CNN）
给比较少的参数，对于DL给比较少的神经元的数目（减少每层神经元数目），让model共用参数，用更少的feature
![输入图片说明](/imgs/2024-07-26/J2BMy6zaB9cdAbjK.png)
但是限制模型太多会造成model bias的问题

![输入图片说明](/imgs/2024-07-26/0pF1HJUBq5W132lW.png)

#### mismatch
![输入图片说明](/imgs/2024-07-26/xy6mwByK2EtldvHL.png)
## 如何选择合适的模型
将training data [Cross-Validation（交叉验证）](https://blog.csdn.net/rocling/article/details/93336487)
![输入图片说明](/imgs/2024-07-26/cUoNWSZmilorUSWL.png)
private testing set 指的是未公开的测试数据
怎样分training set和validation set呢？

把training set 分成N等分
![输入图片说明](/imgs/2024-07-26/wccbCP6ViyK3ATKK.png)
## 为什么用了validation set还会overfitting？
### validation set
![输入图片说明](/imgs/2024-07-29/LoXr3LqYYxuljzbP.png)
先用training set算出不同的H中最好的参数h* ，再将h* 在validation set中的loss算出来，取最低的那一个，对应的h*用到testing set 中

这个过程也可以看作是一种训练，用validation model 来训练
![输入图片说明](/imgs/2024-07-29/3R7BJUHUcxo9sOBg.png)
![输入图片说明](/imgs/2024-07-29/6HqXcgenV32nfs4N.png) 

# optimization失效
## gradient太小或者为0
当gradient为0时，得到的loss仍然不让人满意
有存在 local minima 和 saddle point（鞍点） 的情况
![输入图片说明](/imgs/2024-07-27/Ayz6DJrlTe3pmqzG.png)
> 鞍点（Saddle point）在微分方程中，沿着某一方向是稳定的，另一条方向是不稳定的奇点，叫做鞍点。
> 在泛函中，既不是极大值点也不是极小值点的临界点，叫做鞍点。
> 在矩阵中，一个数在所在行中是最大值，在所在列中是最小值，则被称为鞍点。
> 在物理上要广泛一些，指在一个方向是极大值，另一个方向是极小值的点。

鞍点的gradient也为0
gradient 为0的点被统称为critical point（临界点）
![输入图片说明](/imgs/2024-07-26/t5pKflEWzbrbsczy.png)

如果在saddle point 上，就还可以找到让loss更低的方向，因此要想办法区分 local minima 和 saddle point

### 怎样区分local minima 和 saddle point
在某个点θ’的附近，可以对L（θ）进行泰勒级数近似
![输入图片说明](/imgs/2024-07-26/gT0syR3JTPtzVNEx.png)
![输入图片说明](/imgs/2024-07-26/kCZLjd48RVqKfAIh.png)
因为critical point 的gradient为0，所以消掉绿色那一项，因此可以根据红色的那一项确定error surface的样子，从而确定critical point 的具体性质 
注意 θ’ 是定点哦
![输入图片说明](/imgs/2024-07-26/DdNoU26rJu1QxnCm.png) 

Hessian矩阵还可以告诉我们参数更新的方向

先找到负的特征值，对应的特征向量可以指示更新方向
![输入图片说明](/imgs/2024-07-26/iVV1N9If0moDbcUm.png)
举例，对于只有一组的训练数据（1,1）（x=1,y hat=1），对于model y=w1w2x，在critical point (0,0)上
求Hessian矩阵和特征值
![输入图片说明](/imgs/2024-07-27/tqFlaPTY8xai6Obo.png)
然后找到负的特征值，以及其对应的特征向量，沿着该特征向量的方向更新
![输入图片说明](/imgs/2024-07-27/zsLZW6gasO6eqQ7b.png)
但是实际上，由于计算Hessian矩阵以及其对于的特征值和特征向量计算量太大，在实际操作上我们并不会采用这种方法

假说：当你有非常多参数时，可能局部最小值会很少。因为高维可以选择的路更多
实证研究
![输入图片说明](/imgs/2024-07-27/7LAIieO6NHzUwLzk.png)
minimum ratio为最小比率，当minimum ratio为1 时，说明该点是local minima （越靠近越接近于local minima）
该图表明，即使loss很小也还能再找方向让它更小（处于saddle point）
### batch和momentum算法
为什么要用batch？
使用batch 就可以只要看一个batch的容量的训练数据就可以update一次参数，不使用batch就要看过所有的训练资料再更新
![输入图片说明](/imgs/2024-07-27/qU1yDqOFxMAJp4ii.png)

但是实际上，large batch 的运算时间并不一定就比small batch长。
对于并不是太大的batch，GPU可以进行平行运算因此不会花费较多的时间
所以实际上，
![输入图片说明](/imgs/2024-07-27/FwArMZs1LlekKheo.png)
这样看起来好像是大的batch比较占优势，但是实际上，noise反而会对正确率有帮助
![输入图片说明](/imgs/2024-07-27/mYokg9QF7lf6q7Fc.png)
因为大batch可能会在某个gradient为0的地方被卡住，但是小batch因为采用了不同的loss会算出来不同的gradient，L1被卡住并不意味着L2也会被卡住
![输入图片说明](/imgs/2024-07-27/qrsooSizqd9t7NrT.png)
#### momentum算法（对抗saddle point 或者 local minima）
[深度学习中的Momentum（动量）算法原理](https://blog.csdn.net/gaoxueyi551/article/details/105238182)
在物理世界中，由于动量，小球可以滚过平滑的地方甚至小坡，那么能不能把这种现象应用在gradient descent 中呢？
![输入图片说明](/imgs/2024-07-27/WTTgAT2qzCC1GpYB.png)
gradient descent 加上momentum，与先前只往gradient的反方向移动相比，加上了前一步的移动方向，两者加起来取调整参数
![输入图片说明](/imgs/2024-07-27/CG2sC6kRJQjVfjeO.png)
另一种解读方式是，momentum的update方向不是只考虑现在的gradient ，而是考虑过去所有gradient 的总和
![输入图片说明](/imgs/2024-07-27/bJXUQjpt0eR3f2KF.png)
![输入图片说明](/imgs/2024-07-27/kYue8diZRbGofuvm.png)

## adaptive learning rate（自适应学习率）
除了critical point ， 训练network 的时候我们还会面对其它障碍

当loss不再下降，但gradient却没有很小时，可能是遇到了崎岖的error surface 导致当前的参数一直在山谷的两边徘徊，没办法降到更低点
![输入图片说明](/imgs/2024-07-27/t6EgB3FcgLghs6zs.png)

![输入图片说明](/imgs/2024-07-27/Uv2ybhBXd4SzHnm2.png)
叉叉那里是最小的点，学习率太大到不了local minima，太小移不动

我们希望定制化学习率，让梯度越大学习率越小，梯度越小学习率越大
![输入图片说明](/imgs/2024-07-27/JQumMVQJ9lM6fBPr.png)
t 是迭代次数，i 是参数序号

那么如何计算σ的呢？
——对梯度求 root mean square （均方根值），也就是将每个数值的平方求和后再取平均值的平方根
![输入图片说明](/imgs/2024-07-27/3WJkBRK3hktcpUmN.png)

### [Adagrad梯度下降算法](https://blog.csdn.net/qq_45193872/article/details/124153859)

![输入图片说明](/imgs/2024-07-27/65lhcAuwM4eXKumE.png)

如果采用Adagrad
![输入图片说明](/imgs/2024-07-27/kD4EYGR6Hif970Ny.png)

为什么后面会出现波动的情况（在山谷两边反复横跳，learning rate太大导致的）呢？
因为虽然之前初始的gradient较大（看颜色），但是后面的gradient较小，在经过一段的累加过后σ就会很小，然后learning rate变得很大，导致反复横跳，但是由于反复横跳会到gradient比较大的地方，又会让σ重新变大，步伐又慢慢变小

解决这个问题之一的策略叫 learning rate scheduling 
learning rate scheduling 就是要让η与时间有关
最常见的策略叫 learning rate decay 
也就是迭代的越多让η越小，因为迭代得越多越靠近终点，步伐就要放小

策略之二 Warm Up
让Learning rate 先变大后变小
![输入图片说明](/imgs/2024-07-27/pTGKQ5Hw08pK4mWS.png)

### RMSProp
可以调整现在的梯度和之前的梯度的权重，让现在的梯度占更大的比重，对现在的σ产生更大的影响，现在的梯度大可以让 learning data 变小，更新的幅度更小，反之同理
![输入图片说明](/imgs/2024-07-27/FVssUca0TWq72vbf.png)

### 目前常用的optimization——Adam
[深度学习中的Adam优化算法详解](https://blog.csdn.net/weixin_45981224/article/details/119823926)
### summary of optimization
![输入图片说明](/imgs/2024-07-27/4mCNsJw35q4AJvw5.png)
 
# optimization for deep learning
on-line VS off-line
![输入图片说明](/imgs/2024-07-28/m2D4yYdoONFtOl7e.png)
![输入图片说明](/imgs/2024-07-28/49hFMn0JDTM3UzR0.png)
off-line更简单，但是由于空间和资源的限制，我们通常一次只会处理一对（x,y），接下来主要处理Off-line

## [回顾过去的optimization](https://blog.csdn.net/Hanx09/article/details/105741365/?ops_request_misc=&request_id=&biz_id=102&utm_term=generalization%20gap&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-5-105741365.142%5Ev100%5Epc_search_result_base2&spm=1018.2226.3001.4187)
### 1.随机梯度下降（stochastic gradient descent，SGD）
![输入图片说明](/imgs/2024-07-28/2lYDPjwfe1Av9JVc.png)
### 2.SGDM（SGD with momentum）
会考虑历史梯度的信息，也就是所谓的“动量”（momentum）。这种策略会让模型在每次更新时不仅考虑当前的梯度，还会加入之前几轮更新的方向，这样可以使得学习过程更稳定，尤其是在处理非凸优化问题时，有助于跳出局部最优，持续向着全局最优方向移动。
![输入图片说明](/imgs/2024-07-28/smfwhHJSuHb74tLt.png)
![输入图片说明](/imgs/2024-07-28/P7ZBRivxJD68zgah.png)
由此，当某个点gradient为0时，由于之前行动的影响，update可以继续下去
![输入图片说明](/imgs/2024-07-28/0ddctAP5PK1eXvMV.png)

有一个我自己的问题：在SGDM算法中，由于之前gradient的影响，会在到达真正的global minima时继续移动而使最终的结果不理想吗？

解答：
在SGDM（Stochastic Gradient Descent with Momentum，带动量的随机梯度下降）算法中，之前gradient（梯度）的影响确实会在一定程度上影响参数更新的路径，但这并不意味着算法在到达真正的global minima（全局最小值）时会继续移动而使最终的结果不理想。以下是对这一问题的详细分析：
1. 动量的作用
SGDM算法在SGD（随机梯度下降）的基础上引入了动量（Momentum）的概念。动量可以看作是模型在参数空间中的“速度”，它是过去梯度方向的加权平均。在每次参数更新时，动量会考虑当前梯度和过去梯度的贡献，这有助于加速收敛并减少震荡。具体来说，当梯度方向一致时，动量会累积并增大步长；当梯度方向改变时，动量会起到阻尼作用，减缓参数更新的速度。
2. 对全局最小值的影响
-   **接近全局最小值时**：当模型接近全局最小值时，由于梯度值逐渐减小（接近零），动量的影响也会相应减弱。此时，参数更新的步长主要由当前梯度和学习率决定，而动量的累积效应变得不再显著。
-   **越过全局最小值的风险**：虽然理论上存在越过全局最小值的风险，但在实际应用中，由于学习率通常会随着迭代次数的增加而逐渐减小（或采用其他学习率调度策略），以及动量的阻尼作用，这种风险被大大降低。此外，深度学习模型往往具有高度的非线性和冗余性，使得全局最小值附近通常存在一个相对平坦的区域，即使参数略有偏离全局最小值，模型的性能也不会受到太大影响。
3. 应对策略
为了进一步提高SGDM算法的性能和稳定性，可以采取以下策略：
-   **学习率调度**：根据训练过程中的性能变化动态调整学习率，如在损失函数不再显著下降时减小学习率。
-   **权重衰减（L2正则化）**：通过引入正则化项来约束模型参数的规模，有助于防止模型过拟合并提高泛化能力。
-   **提前停止**：在验证集性能不再提升时提前停止训练过程，以避免过拟合。

综上所述，虽然SGDM算法中之前gradient的影响可能会在一定程度上影响参数更新的路径，但通过合理的策略和调整，我们可以降低这种影响并确保算法能够收敛到理想的结果。因此，在到达真正的global minima时，SGDM算法通常不会因之前gradient的影响而继续移动导致最终结果不理想。

###  3.Adagrad（Adaptive Gradient Algorithm）
一种自适应学习率的梯度下降算法
通过过去的gradient 来调整学习率
![输入图片说明](/imgs/2024-07-28/APxAKLuqIDWZWbRe.png)

### 4.RMSProp
与Adagrad非常像但是做出了改进，确保不会因为前几步的gradient太大导致停下update（因为学习率太小），并且使平方梯度的指数移动平均（EMA）不是单调递增的
![输入图片说明](/imgs/2024-07-28/9wfB6QVgKN2Pn6g2.png)
也可以让目前的gradient占更大的比重，以目前的gradient为主要影响进行更新

### 5.Adam（Adaptive Moment Estimation）
![输入图片说明](/imgs/2024-07-28/KceuVSKtOh3BUA3Z.png)
一开始t比较小的时候，mt 比较小，（1-βt）也比较小，除以（1-βt）可以让mt保持比较稳定的数值，不会因为迭代次数增多而产生较大的变化，vt同理
ε可以在最开始vt为0时避免无穷大的情况

### Adam VS SGDM
![输入图片说明](/imgs/2024-07-28/EcpJZnyLVh1sXHI0.png)
[generalization gap——泛化差距](https://blog.csdn.net/zhangboshen/article/details/72853121)
由于Loss，training function 和 testing function 通常有一些差距；而在flat minima 处，两者之间不会有很大的generalization gap，但是在sharp minima 处，由于gradient 很大，一点点偏差都会导致较大的generalization gap

## SWATS
![输入图片说明](/imgs/2024-07-28/6mn2TJCN3JSubh7b.png)
-   什么时候切换为SGDM
-   如何初始化SGDM的学习率

## 优化Adam
-  Adam的问题之一

在接近终点时，大部分gradient都很小，只有几个batch可以提供有效的方向
![输入图片说明](/imgs/2024-07-28/hP36fDKyib0jqPH7.png)

![输入图片说明](/imgs/2024-07-28/D3RqnXgpNDVogCoV.png)
即使有一步的gradient非常大，也会被限制在最大为![输入图片说明](/imgs/2024-07-28/ePQ7m001jeOodfj6.png)
前面梯度较小，没有提供什么方向信息，但累加起来为1000 η，相比于较大的梯度提供的信息10 倍根号10 η很大，较大的梯度本提供了更多的方向信息，Adam却不能体现。
也就是说，如果大部分gradient都很小，update的大小就会被影响，大的gradient将无法很好地表现出来

**solution:AMSGrad**
![输入图片说明](/imgs/2024-07-28/DWktLqA5oMlLAW1u.png)
减少小gradient的影响，记住之前较大的vt
但是这样只取大的又会导致学习率单调下降的问题

-  Adam的问题之二

在接近终点时，由于gradient 的影响，learning rate 很极端，要么很大，要么很小
![输入图片说明](/imgs/2024-07-28/doXXEvuudhViiCvV.png)

**solution：AdaBound**
![输入图片说明](/imgs/2024-07-28/1QzNtpaH8O9iSj6U.png)

clip函数：限制一个array的上下界
给定一个范围[min, max]，数组中值不在这个范围内的，会被限定为这个范围的边界。如给定范围[0, 1]，数组中元素值小于0的，值会变为0，数组中元素值大于1的，要被更改为1.

但是这些值是由人工来限定的，有些失去了机器学习的意义

## 改进SGDM
SGDM收敛得比较慢，因为它的learning rate 是固定的，没有办法调整，那么能不能找到一个相对比较合适的learning rate 来让收敛速度变快呢？
![输入图片说明](/imgs/2024-07-28/uxbmcr6pNdAk0lwF.png)
周期性调整learning rate ，周期性的原因：在找到一个较好的点时在附近探索有没有更好的
![输入图片说明](/imgs/2024-07-28/jqcJTEzLlRUHcmYU.png)
 
![输入图片说明](/imgs/2024-07-28/wUsCFDuUqfnKrtq9.png)
warm-up ——> 预热

那么Adam 需要预热吗？
![输入图片说明](/imgs/2024-07-28/NSwmUm5a0HKwkvm1.png)
由图可知，迭代次数少的时候，梯度分布就比较混乱，但在有预热的情况下，就呈现出高斯分布，所以需要预热（图中横轴为gradient distribution，从左往右增大，纵轴为迭代次数，从上往下增大）

![输入图片说明](/imgs/2024-07-28/D4TpsnFzwzexKkaa.png)

distort——>扭曲
[EMA——指数移动平均](https://blog.csdn.net/Dteam_f/article/details/118405875)
EMA也就是![输入图片说明](/imgs/2024-07-28/A0t9rYT0gG753Bri.png)
如果前几次的 learning rate 太大，容易导致反复横跳，得到的结果也会不稳定，那么应该怎样warm-up呢？


![输入图片说明](/imgs/2024-07-28/SxIlxvgLhRbUNtg7.png)
看不懂。。。
大概是算出来rt来控制learning rate

![输入图片说明](/imgs/2024-07-28/HrOxnHzR4rRgJZND.png)

## Lookahead
每走几步就会检查一下现在的方向是否好
可以作为其它优化器的通用包装
![输入图片说明](/imgs/2024-07-28/0KTcdJQvF3um6XuK.png)

![输入图片说明](/imgs/2024-07-28/nm5YXJWqRD4bW9AW.png)是每一轮的起点，从![输入图片说明](/imgs/2024-07-28/v5X5dlBFukBBdwGZ.png)出发不断优化，走到终点![输入图片说明](/imgs/2024-07-28/sucETbiA5h4Qzjhm.png)，然后取出以起点和终点为端点的线段上的某个点为![输入图片说明](/imgs/2024-07-28/TRSU81ftkUgxDSNm.png)，这个点即为下一轮的起点。

![输入图片说明](/imgs/2024-07-28/2xITGEfnxA9WjAgO.png)

## NAG算法（Nesterov Accelerated Gradient）
Nesterov是人名
在SGDM的基础上，估测下一步的gradient
![输入图片说明](/imgs/2024-07-28/NDuXsVgvukcFICo5.png)
超前部署 

## Adam的超前部署——Nadam
![输入图片说明](/imgs/2024-07-28/tvZ4d1jOWZE9e641.png)
## L2正则化
在θ的平方前乘一个系数（正则化系数），来使θ不要太大（因为最优化是使L减小，在L减小的过程中，前面系数的大小会限制后面参数的大小）
θ太大可能会对应于比较崎岖的low surface，容易出现generalization gap的问题
![输入图片说明](/imgs/2024-07-28/Y9skq1BVeQeX6uST.png)
在迭代过程中，如果不加γθt-1，为了达到正则化效果，要在最后一项加上γθ（weight decay）

不加的优化器：（很有实用性）
![输入图片说明](/imgs/2024-07-28/p9eHUP8P548M5SrE.png)

## 有助于optimization的一些事情
### 增加model的随机性，进行更多探索
![输入图片说明](/imgs/2024-07-28/SjKyJhsTrW56HZG3.png)
1.shuffling（搅乱）
打乱输入数据的顺序，每次重新切分batch，这样算出来的gradient方向比较有变化
2.[dropout](https://blog.csdn.net/weixin_42475060/article/details/128862411?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172217113016800207075571%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172217113016800207075571&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-128862411-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=dropout&spm=1018.2226.3001.4187)
dropout是一种防止过拟合，减少神经元之间的依赖性的方法
但是在这里也可以被视为一种增加随机性的方式
3.gradient noise
算完gradient noise 后假设一个Gussian noise，随着t增大Gussian noise会减小

### 调整learning rate
1.warm—up
让learning rate先小后大
2.[curriculum learning（课程学习）](https://blog.csdn.net/NGUever15/article/details/122240905?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172217171416800213048410%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172217171416800213048410&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-122240905-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=curriculum%20learning&spm=1018.2226.3001.4187)
先用比较接近平均值（或者说噪声比较小）的数据来训练模型，再用比较复杂的数据
3.[fine-tuning（大模型微调）](https://blog.csdn.net/qq_39172059/article/details/136693607?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172217189816800184119400%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172217189816800184119400&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-2-136693607-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=fine-tuning&spm=1018.2226.3001.4187)

![输入图片说明](/imgs/2024-07-28/7WPoTHMfft8e1fga.png)
### 其它做法
1.[Normalization(标准化)](https://blog.csdn.net/u011092188/article/details/78174804?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172217200616800172576860%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172217200616800172576860&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-78174804-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=normalization&spm=1018.2226.3001.4187)
2.正则化
![输入图片说明](/imgs/2024-07-28/BsoXViYqL3xYPjdR.png)

## summary
![输入图片说明](/imgs/2024-07-28/KnbnJpNhJZnVrnrV.png)

![输入图片说明](/imgs/2024-07-28/n8mfJfyFUJstSKKX.png)

![输入图片说明](/imgs/2024-07-28/AkJgdmoOW9eRUZqd.png)

# network 的架构之一——CNN
CNN——convolutional neural network（卷积神经网络），主要用于影像相关

影像分类问题
![输入图片说明](/imgs/2024-07-28/LVuS9MzqmnS62Zyt.png)
输出是one-hout vector，有多少维意味着能辨识出多少中不同类的东西

如何将影像作为输入？
把图像看作三维的tensor（张量，也就是矩阵向任意维度的推广）
network 的输入是向量，所以现在的工作是要把图像转化为向量

![输入图片说明](/imgs/2024-07-28/uRUOwC8lbFrS6YJr.png)
把图像抽成3 *100 *100的向量，每一维的数值代表了某一个位置的某一个颜色的强度

如果用fully connected network
![输入图片说明](/imgs/2024-07-28/FpfFXYxvR17w5Jpb.png)
我们会需要非常多的weight 的数值，容易造成overfitting，那么，我们真的需要用“fully connected”来处理影像辨识问题吗？

## 观察影像辨识问题的特点
### 1.用一些重要的关键特征判断图像类别
比如看到鸟喙、鸟眼睛、鸟爪等等关键特征就判断这是一只鸟
![输入图片说明](/imgs/2024-07-28/qF7DjpJGEIwyCJKF.png)
简化一： 设定receptive field（感受域）
每个神经元不关心整张图片，只关心自己的那个receptive field
![输入图片说明](/imgs/2024-07-28/Zdh2EQWorAPZpIcr.png)

receptive field的划定由人工决定，可以有重叠、有不同的大小、考虑不同的channel，不同的形状等等
![输入图片说明](/imgs/2024-07-28/P8rmPvOjuSqJunmc.png)


[经典的receptive field设定](https://blog.csdn.net/weixin_44116706/article/details/131135925?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172222035116800207054887%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172222035116800207054887&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-131135925-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=kernel%20size&spm=1018.2226.3001.4187)
1）考虑所有的channel
2）kernal size（卷积核）不会太大（kernal size是receptive field的长x宽）
3）有多个神经元会感知同一个感知域（比如64个，或者128个等）
4）stride（步幅）是视野域（卷积核的形状映射在输入数据上的窗口）每次移动的距离，一般不会设得太大，希望 receptive field 之间有重叠
5）按照 stride 移动可能有超出影像范围的情况，这时候就要做padding（填充），超出影像范围的全填0，填其它数字也可以

![输入图片说明](/imgs/2024-07-29/JjI60nbONdvBkewp.png)

### 2. 相同的图案出现在不同的地方
侦测相同的图案做的工作是一样的，只是图案出现在不同的地方而已，那么能不能简化这个工作呢？
简化二：让不同感知域的神经元共享参数
![输入图片说明](/imgs/2024-07-29/kmQs70mtwn3AUHgt.png)

常见的共享方法：
 ![输入图片说明](/imgs/2024-07-29/8yz01pRgsWHc0DAC.png)
 filter是过滤器的意思

![输入图片说明](/imgs/2024-07-29/Cza0ThzdU3tkPQbl.png)

### 基于 filter 的CNN 的另一种解释方法
filter 在图像中抓取 kernel size 那么大的 pattern
filter 在这里是以model 的 parameter 为数值的tensor，这些parameter要通过gradient descent 得到
![输入图片说明](/imgs/2024-07-29/lnSvQff9yGVeCDWD.png)

在image中取3x3的方格，每个格子中的数字与filter对应位置的数相乘后相加得到结果，然后取stride为1，不断地取相邻1格的3x3方格做运算（也就是扫过去），最后找出最大的结果，就是pattern 出现的地方
每一格通过相乘后相加得到的数字群叫做 feature map 

不同的filter得到的feature map叠在一起看作形成了新的图像，每一层feature map都是一个channel 
对于下一层convolutional layer ，channel 就是上一层filter的数目
![输入图片说明](/imgs/2024-07-29/cnygNVGnyJXEq4Ql.png)

那么filter一直取3x3，会不会没有办法全面地观察到pattern呢？
实际上，因为下一层对应的3x3其实对应的是上一层的5x5，因为下一层的feature map的一个数字，实际上是通过上一层3x3计算出的，个人觉得像是一种映射吧
![输入图片说明](/imgs/2024-07-29/dvHx5DxHKFjAcIuB.png)
所有叠得越深，看的影像范围越大

### 综合两种解释
第一种解释中共用的参数就是第二种解释中的filter 
（我理解是filter中的数字对应的就是权重，是这样吗？）

![输入图片说明](/imgs/2024-07-29/gtxKwZU3gGtELoVY.png)
虽然这里忽略了bias，但是实际上这些filter中还是有bias的数值的

![输入图片说明](/imgs/2024-07-29/Ij0wEVwgNByENWxg.png)
共享参数实际上就是用filter扫过一张图，这也就是convolve（卷积的由来，扫过是卷，相乘是求积）

![输入图片说明](/imgs/2024-07-29/VIVv6JwQK3VOmNLK.png)

### 3.subsampling（二次抽样）
![输入图片说明](/imgs/2024-07-29/Fd2fjPawiH9u1dxH.png)

#### pooling（共用）
pooling是一种操作，本身没有参数，行为是固定的，不需要依据data进行学习，目的是减少运算量
pooling 的一种方式——max pooling
分组，然后在组里面选代表，组的大小和代表的选择方式都可以自己定，max pooling 选每组最大的
![输入图片说明](/imgs/2024-07-29/wm6063Q2fb6F6pyz.png)
![输入图片说明](/imgs/2024-07-29/4zkvKEaHa4leL6HV.png)

pooling后channel不变但是长宽变小
在实际操作上，convolution和pooling交替重复使用
不过pooling也会对performance有影响（毕竟少了一些特征）所以如果侦测很精细的东西pooling可能会造成一些影响
![输入图片说明](/imgs/2024-07-29/gO55GtRIiwsc1Xrs.png)

![输入图片说明](/imgs/2024-07-29/XKipJkmlFDu0CYJi.png)
flatten是把影像矩阵拉直变成向量

## 应用
下围棋
![输入图片说明](/imgs/2024-07-29/lVn1OvWQmbZUiAkw.png)
48个channel是围棋高手设计出来的
 
 下围棋和影像辨识有共通之处
![输入图片说明](/imgs/2024-07-29/GsVsP4re7Mb4Nfyq.png)
![输入图片说明](/imgs/2024-07-29/XK7RWWk9MpFBOOhe.png)

除此之外的应用还有语音处理、NLP等等，不过这些应用中对感受域的设计是不同于影像处理的

但是CNN不能处理影像放大缩小或者说旋转的问题，不过spatial transformer layer可以处理这个问题
![输入图片说明](/imgs/2024-07-29/lVYMvNBr5PcPu5iO.png)




# DL好在哪里
回顾：![输入图片说明](/imgs/2024-07-28/t9FU2rS24NA7XRdT.png)
![输入图片说明](/imgs/2024-07-29/TwtitOEQ8VRe73IX.png)
## 神经网络为什么要隐藏层？
![输入图片说明](/imgs/2024-07-29/eLTvk1TgUF1xTnJ1.png)
只要分段够多就可以贴近曲线

![输入图片说明](/imgs/2024-07-29/nFtJ05H98aic0LHP.png)
![输入图片说明](/imgs/2024-07-29/OVl8o0EZHIb57w5a.png)

我们设立了隐藏层神经网络，其中的每个神经元可以造出阶梯型functon，由此产生出任何的piecewise linear function，来逼近任何function，神经元也可以是ReLU
![输入图片说明](/imgs/2024-07-29/z2TvLafYTwYQy9uk.png)
![输入图片说明](/imgs/2024-07-29/yDF5bka7RuTtImHt.png)

为什么是变深而不是变胖呢？
![输入图片说明](/imgs/2024-07-29/1CMrROOGk4yPHWzV.png)
深度学习模型大，H大，理想的loss就低，资料多，现实和理想就可以接近

![输入图片说明](/imgs/2024-07-29/qVMYk5i7pKPxq0Qo.png)

虽然一层神经元就可以表示所有function，但是多层会更高效
![输入图片说明](/imgs/2024-07-29/NnqqwKB1VH0lu7uZ.png)

layer做的事情：
就像剪纸时把纸折叠起来
![输入图片说明](/imgs/2024-07-29/Dv71gVaYqHQc5lyk.png)

![输入图片说明](/imgs/2024-07-29/Qn1SBCzMzJsRZWfB.png)
![输入图片说明](/imgs/2024-07-29/S0Vbd97aLauFkRy8.png)
![输入图片说明](/imgs/2024-07-29/9gaMKuN0tIN2EGdw.png)
所以DL适用于复杂并且有规律的function


# 特别但有用的network架构
## [Spatial Transformer Layer](https://blog.csdn.net/WZZ18191171661/article/details/100621925?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172225390516800227497975%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172225390516800227497975&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-100621925-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=Spatial%20Transformer&spm=1018.2226.3001.4187)
在CNN最后提了一下

Spatial Transformer Layer是一个layer，放在了CNN的前面，用来转换输入的图片数据，其实也可以转换feature map
![输入图片说明](/imgs/2024-07-29/YUw5TrFnwtNRAg4X.png)

### 怎样移动图像或者fearute map呢
对weight进行不同的设计
![输入图片说明](/imgs/2024-07-29/STL0MfXgHPzcsZME.png)
l代表层数；n,m是下标，代表l层的行和列；i,j是l-1层的下标

![输入图片说明](/imgs/2024-07-29/9ZoDIXuBUuYHvtAQ.png)
l层被指向的数字（比如a23 l）对应的l-1层的指出去的数字（比如a13 l-1）的weight是1，其余情况都为0

如何找到这些weight呢？
用神经网络来控制层与层之间的连接
![输入图片说明](/imgs/2024-07-29/702o8O5Ef57uLkAN.png)

图像的放缩和移动
![输入图片说明](/imgs/2024-07-29/gIjQx8pUOm6CDFT3.png)

图像的选择
![输入图片说明](/imgs/2024-07-29/7uePzcxzDfbmBVDn.png)



那么可以得出，描述这个仿射变化的其实是6个参数
![输入图片说明](/imgs/2024-07-29/b6l8EcxavL1AhuNX.png)
也就是说，l层（x，y）的input就是l-1层（x'，y'）的output，已知x,y求x',y'

如果参数有小数，得到的坐标答案有小数
![输入图片说明](/imgs/2024-07-29/manOFC0uJuOglAom.png)
也就是说，虽然参数发生了微小的改变，但是输出并没有变，所以不能用gradent descent来解

所以需要做interpolation（插补）
![输入图片说明](/imgs/2024-07-29/SX1lPxwgKlLrt1fI.png)
让a22 l的值随着参数的变化也产生变化

![输入图片说明](/imgs/2024-07-29/MOc4MfUh4ybtWYfL.png)
Spatial Transformer Layer 可以放在任意function map的后面，可以有不止一个，得到多个output 后进行处理

![输入图片说明](/imgs/2024-07-29/sRk6jbirCykAaJSW.png)

## 自注意力机制（Self-attention）

输入：一群向量（vector set as input）

输出：
1.与输入向量数量一样的label（label可以是数值或者类别）
应用：例如对句子中的每个单词进行词性标注，对每一段语音进行辨识，以及判断这个客户会不会买某一件商品
![输入图片说明](/imgs/2024-07-30/mIyLguvSGMNKS1z5.png)

2.只输出一个label
应用：例如对句子做情感分析（正面、负面、中立等）、分析一段语音的说话者是谁、判断分子的特性（亲水性等等）
![输入图片说明](/imgs/2024-07-30/LnSYZMwR4gxqRWRU.png)

3.输出label的数目不确定，让机器来决定label的数目
![输入图片说明](/imgs/2024-07-30/YP5dkT8KtftxZNUo.png)

接下来终点讨论输入向量数和输出label数一样的情况，也叫sequence labeling

引入自注意力机制的目的：
神经网络接收的输入是很多大小不一的向量，并且不同向量与向量之间有一定的关系，但是实际训练的时候无法充分发挥这些输入之间的关系而导致模型训练结果效果极差。比如机器翻译问题(序列到序列的问题，机器自己决定多少个标签)，词性标注问题（一个向量对应一个标签)，语义分析问题(多个向量对应一个标签)等文字处理问题。

针对全连接神经网络对于多个相关的输入无法建立起相关性的这个问题，通过自注意力机制来解决，自注意力机制实际上是想让机器注意到整个输入中不同部分之间的相关性。

### sequence labeling
![输入图片说明](/imgs/2024-07-30/SJtWJNaokMz3zRKt.png)
要考虑上下文，如果想选用足够大的window来覆盖整个sequence，那么会面对sequence长短不一的问题，那么就应该选用比最长的sequence还要长的window才能覆盖，这将会面临fully connected network参数过多导致的计算量过大和容易overfitting的问题。self-attention正是用于考虑整个输入的sequence的资讯

![输入图片说明](/imgs/2024-07-30/OlCZiZSGErcbozN1.png)
self-attention输出的向量（带黑色方框的）是考虑了一整个sequence之后得到的

self-attention可以叠加很多次，与fully connected network 交替使用

![输入图片说明](/imgs/2024-07-30/kceWuKE3Aoh33usK.png)
得到每个b都考虑了所有的a

#### 具体操作
怎样产生一个输出（比如b1）
1.根据a1找出这个sequence中跟a1相关的其他向量
输入的sequence中每一个向量和a1的关联程度用 α 来表示，用一个计算attention 的模组（以两个向量为输入，输出 α ）

计算 α 的常见做法 Dot-product（点积）
把输入的两个向量分别乘上不同的矩阵，将得到的向量做点积，得到的结果就是 α 

介绍的另一计算 α 的方式 additive
把输入的两个向量分别乘上不同的矩阵，将得到的向量相加，把和向量通过矩阵变化得到最终的 α 
![输入图片说明](/imgs/2024-07-30/vDOKFpXxSVIZV3o7.png)

计算 α 
![输入图片说明](/imgs/2024-07-30/g4CGbU4mMPzteyDB.png)
q是指query（查询），k是指key
a1到q1和k1都经过了矩阵变换
[activation function](https://blog.csdn.net/weixin_39910711/article/details/114849349?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172231130716800188553048%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172231130716800188553048&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-114849349-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=activation%20function&spm=1018.2226.3001.4187) （激活函数）不一定要用softmax，也可以用其他的

![输入图片说明](/imgs/2024-07-30/fnsOXaLbQOovvjtX.png)

![输入图片说明](/imgs/2024-07-30/cUOkHm5R118hQZqt.png)
b1到b4是同时被计算出来的
![输入图片说明](/imgs/2024-07-30/Vc1gXttdnRj4QPQf.png)

#### 用矩阵乘法解释self-attention如何运作
![输入图片说明](/imgs/2024-07-30/2QfPMLLNbRPfq2fY.png)

![输入图片说明](/imgs/2024-07-30/f0R4zIiK0AJfuxOd.png)
横着的方块代表行向量

![输入图片说明](/imgs/2024-07-30/OFF66EzZd1mKSeJe.png)
回顾一下矩阵乘法
![输入图片说明](/imgs/2024-07-30/eHl4onq463RUAgYU.png)

![输入图片说明](/imgs/2024-07-30/OepLZe7dcBScyWdr.png)

### 进阶版本
找多个q，不同的q负责不同种类的相关性

![输入图片说明](/imgs/2024-07-30/QcYfiqY6i3HqV1UY.png)
i，j代表位置（例如a1 a2）
所有变换还是通过矩阵得到（矩阵是学习来的）
然后1类的q和1类的k作内积，得到的 α 再乘1类的v，所有结果相加得到bi,1
同样的操作得到bi,2等等其他类关系的 b 
再通过矩阵得到一个最终结果
![输入图片说明](/imgs/2024-07-30/ON5NV6peFZi2pADN.png)

### 位置的资讯
![输入图片说明](/imgs/2024-07-30/Lb6mrI989w496eM2.png)
可以通过不同的方式进行positional encoding，下面是一些方法
![输入图片说明](/imgs/2024-07-30/kSsBR3wqJwHxiymj.png)

### 应用
1.被广泛应用于自然语言处理，BERT模型和 transformer 架构都有用到self-attention
2.语音辨识
 由于做语音辨识时是不断截取一段来做（一般是截25ms，然后移动10ms）作为输入，所以一句话的向量可能会非常长，计算量很大
因此会使用 truncated self-attention （truncated 截取的）
即在做self-attention时不看一整句话，只看一个小的范围
![输入图片说明](/imgs/2024-07-30/PhD0G1HCthYHn6EK.png)

3.影像辨识
把每个pixel当成一个三维的向量
![输入图片说明](/imgs/2024-07-30/5qNiYCBfRZIV8C9S.png)
![输入图片说明](/imgs/2024-07-30/1eO0N5ZDi1mJPgpf.png)

4.用于图表
![输入图片说明](/imgs/2024-07-30/9yoD6IolDp8PX7XS.png)


### self-attention VS CNN
![输入图片说明](/imgs/2024-07-30/oyCpiBVOnjPsqFke.png)
CNN 是人工划定感受域，self-attention用机器学习来决定哪些相关

![输入图片说明](/imgs/2024-07-30/8GFpnh5a7VHmZ1Zh.png)
![输入图片说明](/imgs/2024-07-30/uGNOnyUfrTPKJDVa.png)

### [RNN](https://blog.csdn.net/qq_32241189/article/details/80461635?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172232747116800172527715%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172232747116800172527715&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-2-80461635-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=RNN&spm=1018.2226.3001.4187)
![输入图片说明](/imgs/2024-07-30/3Kx8qmE4jXyjE8Lp.png)

# self-attention的变形
self-attention的痛点
![输入图片说明](/imgs/2024-07-31/I8lW5u5TEwta9k2Y.png)
得到 N X N 的attention matrix 的计算量太大。尤其是在input vector非常长的时候

![输入图片说明](/imgs/2024-07-31/PVxPACDDYxIM9WMD.png)
当N非常大的时候，self-attention 的计算占主导地位，优化self-attention才会较为有效，因此下面的方法都是基于input vector很长的情况

## 1.基于人工知识跳过一些运算
### Truncated Attention/Local Attention 
基于人类的知识填充 attention matrix 中的一些值，以此来跳过一些运算
举例：![输入图片说明](/imgs/2024-07-31/3bSy6EquVMlw8H4q.png)
虽然加速了运算，但不一定能取得很好的结果

### Stride attention
跳过比较近的格子看比较远的信息
![输入图片说明](/imgs/2024-07-31/mp2bNQCMSe4HHjeT.png)
左边的图是跳两个看第三格的，右边的是跳过一格看第二格的，灰色的是设为0

### Global Attention
选出一些特别的作了标记的元素去和其他所有元素进行运算（也是一种人工智慧啦）
作标记：1.在原来的sequence中选取，比如选取transformer中的开始标志，或者句号等等
2.自己添加一些记号

![输入图片说明](/imgs/2024-07-31/MAKYSUVGaVvtJ1Wf.png)
横轴和纵轴分别代表q和k，special token attend 所有向量，也被所有向量attend 

### 选择哪一个呢？
![输入图片说明](/imgs/2024-07-31/dICcTcz4sNaKOJNr.png)

![输入图片说明](/imgs/2024-07-31/yXd0OHyK7JqdHJNL.png)

## 2. 聚焦于关键部分
![输入图片说明](/imgs/2024-07-31/QrcbM9GoY5kImq5V.png)
那么怎么估计哪些地方的attention小呢？
——clustering（聚类）
![输入图片说明](/imgs/2024-07-31/a53Td6vVZs7IiURk.png)

把query和key大概分类，只有query和key属于同一类的向量才计算attention
![输入图片说明](/imgs/2024-07-31/VhDvzapnzDxRbYBd.png)

## 3.Sinkhorn Sorting Network 
用训练另一个network（为了方便表达，把这个network用NN来表示）来决定某个格子要不要做attention 

把输入的每一个vector分组（比如说输入了100个vector分成10组），每一组通过NN得到一个vector（目的是简化运算），通过这样得到了一组vector，再把这组向量放大到N X N，大小等同于attention matrix ，现在的目标是把得到的这组vector network变化成决定要不要计算attention的matrix（这个matrix里面每个格子的值是1/0，1代表要计算q*k的值，0代表不计算）
但是得到的vector set的值存在小数，而决定要不要计算attention的matrix中只有0和1
所以NN是有特殊方法把vector set的值变成0和1的，且这个过程是可以微分的，所以NN是和整个network一起被train出来的
![输入图片说明](/imgs/2024-08-01/8wYdgDrhHF8fPiUW.png)

## 4.减少Key的数量
实际上，我们的attention matrix大多 秩比较低 ，也就是说attention matrix中有很多列是线性相关的，那么我们能不能把重复的列剔除出去呢？

从N个key中挑选K个具有代表性的key，在value vector 中同样挑选出K个
让N个key与每个query算出attention weight，attention weight与对应的value vector相乘后加和得到Output
![输入图片说明](/imgs/2024-08-01/FabQMDDRv0in9Byo.png)

怎么选出有代表性的key？
![输入图片说明](/imgs/2024-08-01/aAj5dlH4MIvGaR6o.png)
1.用CNN把sequence缩短
2.把k个vector看成是dxK的矩阵，乘一个N x K 的矩阵，得到了d x K的矩阵

##  Linear Transformer 
attention 运算可以看作是一连串的矩阵乘法，能不能加速这个矩阵乘法呢？

先回顾一下
![输入图片说明](/imgs/2024-08-01/QSP7Vx62TCdNvkoK.png)
这个d'可以等于d也可以不

按照原来的方法计算，需要做乘法的次数为——
![输入图片说明](/imgs/2024-08-01/PJVy2xf4oj5O1Qv2.png)
这里先忽略了softmax

但如果交换矩阵乘法的次序（不影响结果）
![输入图片说明](/imgs/2024-08-01/ir6V2y3KUwKU41bp.png)

两种方法需要的乘法次数有很大的差异
![输入图片说明](/imgs/2024-08-01/pYcSZDotDazMgAww.png)

## Synthesizer
不由qk产生attention，把attention作为network的参数
![输入图片说明](/imgs/2024-08-01/uFvFcSHeOXa4qIkV.png)

## summery
![输入图片说明](/imgs/2024-08-01/3D7o3pt5mouyFzG5.png)










# RNN（recurrent nerual network）
## 目的
有时候，我们希望我们的神经网络是有记忆力的，来解决同样的Input但是有不同的output这样的问题，比如记得文段的上下文以此判断同一个词汇属于什么不同的类别，比如买票通过上下文确定同一个地名是目的地还是出发地
## 工作原理
![输入图片说明](/imgs/2024-07-31/7FLXigZwNLjII6eI.png)
![输入图片说明](/imgs/2024-07-31/Cuf93UYzqwjnDAMR.png)
memory 里面存着2和2，绿色的神经元=1 * 1+1 * 1+2+2=6，红色的神经元=6 * 1+6 * 1=12，再把绿色神经元的值（6）存到memory中
![输入图片说明](/imgs/2024-07-31/QtHnSPZgmzPEQNMz.png)


![输入图片说明](/imgs/2024-07-31/2bkhdE6ZdjUDsPlF.png)
一个关键元素就是一个槽位(Slot)
![输入图片说明](/imgs/2024-07-31/XlyIfCHd5prha8MK.png)

RNN当然也可以做很多层
![输入图片说明](/imgs/2024-07-31/akojO663qcjcBwY6.png)

## 变形
### Elman network&Jordan network
Elman network：将hidden network 的值存起来，在下一个时间点再读进来
Jordan network：把整个Network 输出的值存起来，在在下一个时间点再读进来
![输入图片说明](/imgs/2024-07-31/McFd3RaEPX8S4iKf.png)
传说(?)Jordan network 的表现会更好，因为hidden network 是没有targer的，它学到什么东西是比较难控制的，而网络的输出是有target 的
### bidirectional RNN（双向RNN）
同时训练两个方向的RNN，把他们的hidden network拿出来接到output layer
![输入图片说明](/imgs/2024-07-31/AjG9Q0aicy5ybIlx.png)
好处：对input的观察范围更广




## Long Shotr-term Memory（LSTM）
LSTM有三个大门

当network的其他部分想要在memory中写入值时，要通过input gate，input gate 的开关决定了是否能够把值写入memory，而这个开关是由神经元来决定的
类似的，memory输出也要通过output gate，output gate决定network的其他办法是否能够读取memory中的值
forget gate 决定什么时候把存储在memory里的值forget掉，什么时候保留
![输入图片说明](/imgs/2024-07-31/sw7uc7My0n5NraT2.png)
![输入图片说明](/imgs/2024-07-31/RnhIy6C1hnirfLYW.png)
sigmoid方程得到的介于0和1之间的值 代表这个门打开的程度，0是关，1是开，c'代表的是在memory中的新值，a是输出
值得注意的是，当f(zf)（forget gate通过sigmoid 方程得到的值）为1时，代表的是保存上一个c的值，为0时是忘记上一个c的值

![输入图片说明](/imgs/2024-07-31/aS4vyVSXLmZsfgVU.png)
![输入图片说明](/imgs/2024-07-31/ViI5oWUTTsnjZe6S.png)
4个输入都是数值，这些数值是通过输入的向量经过线性变换得到的，线性变换的weight和bias通过训练得到。图示为对第一个向量进行运算

与原来的区别
![输入图片说明](/imgs/2024-07-31/yyZpzpJ0C8IvQ0hO.png)
![输入图片说明](/imgs/2024-07-31/QE5rbdwo7WtGiMNW.png)

![输入图片说明](/imgs/2024-07-31/8EIkPvyv4w6fbNwp.png)
ct-1是每一维是 每个memory中的值 的向量，xt经过向量变形得到zf zi z zo，这些z都是向量，输入到memory cell中的值是每一个向量中的一维

![输入图片说明](/imgs/2024-07-31/WJjwbbHml0Xo4zg7.png)

再叠一下层
![输入图片说明](/imgs/2024-07-31/7punfAtbfXxDR9Sp.png)
### learning target
![输入图片说明](/imgs/2024-07-31/WhyTZKS9vAZ4THOg.png)
要依照句子顺序来输入，这样 才能正确获得上下文信息
分类选项里要设置other的one-hot vector

## Backpropagation through rime
需要考虑时间的反向传播
RNN 进行gradient descent 的方法
![输入图片说明](/imgs/2024-07-31/xapawgwyWIYYYSWn.png)

> 反向传播通过时间（Backpropagation Through Time，简称BPTT）是一种用于训练长短期记忆网络（Long Short-Term Memory, LSTM）和其他类型的递归神经网络（Recurrent Neural Networks,RNNs）的算法。在RNN中，信息会沿着时间序列传递，而传统的反向传播由于梯度消失或爆炸的问题，在处理长序列时效率低下。BPTT通过将整个序列分为若干小段，对每一段进行单独的前向传播和反向传播计算，然后累加所有片段的误差梯度，以此解决长依赖问题。
> 
> 具体步骤包括：
> 
> 1.  **前向传播**：从输入开始，逐时间步预测下一个状态和隐藏状态。
> 2.  **误差计算**：根据当前时间步的实际值和预测值，计算误差。
> 3.  **反向传播**：将误差逆序地传播回每个时间步，更新权重。
> 4.  **梯度累积**：对每个时间步的梯度进行累加，得到完整的误差梯度。
> 5.  **权重更新**：利用反向传播得到的梯度调整模型参数。

## RNN的训练
RNN 的训练非常困难
![输入图片说明](/imgs/2024-07-31/NbH97WK2NifmcyvX.png)
容易出现像绿色曲线那样的Loss曲线

![输入图片说明](/imgs/2024-07-31/d9JX2ygSM7ctoP7E.png)
因为error surface 非常不平，有的地方很平坦，有的地方很陡峭，所以容易造成突变
solution：clipping（剪切），即限制gradient的大小，当gradient大于某个设置好的数的时候，就让gradient等于这个数
![输入图片说明](/imgs/2024-07-31/SMIIgrnk6JPmH2Fg.png)

为什么RNN有如此崎岖的error surface呢？
![输入图片说明](/imgs/2024-07-31/zKp3GyZbqieaTBfX.png)
由于同一个weight在不同的时间点会被反复使用（从memory接到神经网络），所以它的一点点改变都会造成非常的的影响（比如1和1.01），但是有的改变又不会造成很大的影响（比如0.99和0.01）

solution：
![输入图片说明](/imgs/2024-07-31/oMfi9pzSStvqluPP.png)
LSTM可以解决某些地方gradient很平坦的问题，但是不能解决gradient爆炸的问题
解决某些地方gradient很平坦的问题后，我们就可以把learning rate设得小一些

那么LSTM是如何解决的呢？
RNN每次都会把memory中的值覆盖掉，但是LSTM只有当forget gate打开时才会进行覆盖操作，而且由于输入与memory中的值进行相加，它的值就会一直影响后面的结果
![输入图片说明](/imgs/2024-07-31/kmbQvDdULd1zF8Q0.png)
所以我们会尽量让forget gate不要启动（比如把bias设得大一些）

**Gated Recurrent Unit**
比LSTM简单，只有两个门，把 input gate 和 forget gate 综合起来，在input 之前要先forget（旧的不去新的不来）

除此之外的solution还有
![输入图片说明](/imgs/2024-07-31/x0EqGab3Ky7GkMBR.png)

## RNN的应用
1.输入一组向量输出一个向量：比如情感分析
2.输入一组向量输出一组向量，但是要求输入长度大于输出长度：比如语音辨识 
下面是语音辨识的例子
 ![输入图片说明](/imgs/2024-07-31/I2MUydWPsNoozZZx.png)
 那么怎么区别“好棒棒”和“好棒”呢？——[CTC](https://blog.csdn.net/weixin_52862386/article/details/130748786?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172242871616800185831527%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172242871616800185831527&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-2-130748786-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=CTC&spm=1018.2226.3001.4187)
![输入图片说明](/imgs/2024-07-31/PUpQZ45nspIRvt9w.png)
CTC怎么做训练呢？
列出所有的可能
![输入图片说明](/imgs/2024-07-31/uhMb2dGifGf8gs6T.png)

3.无限制的输入一组向量输出一组向量（不要求入>出）
![输入图片说明](/imgs/2024-07-31/NwWwPpgtMtPZUxi0.png)




# transformer
![输入图片说明](/imgs/2024-07-30/abOVvUdqt41rXimK.png)

seq2seq model
![输入图片说明](/imgs/2024-07-31/ZkK82uIAIjySRpuh.png)

## encoder
来看看transformer的encoder结构
![输入图片说明](/imgs/2024-07-31/5Nz7CaNllIqbTe8g.png)

x经过多层block得到h，每个block 在做多个layer做的事
![输入图片说明](/imgs/2024-07-31/onsc0qlLGpKwPWVo.png)

实际上，每个block做的事情要更复杂
为了能学习到输入和输出之间的差异，block还运用了[residual connection](https://blog.csdn.net/qq_43700729/article/details/136626602?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172239181116800227421427%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172239181116800227421427&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-136626602-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=residual%20connections&spm=1018.2226.3001.4187)

![输入图片说明](/imgs/2024-07-31/2JmPGSI9e4vXvvCW.png)
norm 指的是[layer normalization](https://blog.csdn.net/weixin_51176105/article/details/134758603?ops_request_misc=&request_id=&biz_id=102&utm_term=layer%20normalization&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-134758603.142%5Ev100%5Epc_search_result_base2&spm=1018.2226.3001.4187)

![输入图片说明](/imgs/2024-07-31/99249mpqzeSe8fat.png)
这个结构不一定就是最好的，norm的位置不一定要放在这里，也可以放别的地方

## decoder
### autoregressive(AT)
![输入图片说明](/imgs/2024-07-31/TIR0r37JvnpNULXg.png)
size V=输出语言词汇集的长度，比如中文的话就是常用汉字的个数

![输入图片说明](/imgs/2024-07-31/D2MC8JE6Kf1i7PcB.png)
前一级的输出是下一级的输入，可能会存在error propagation（误差传播的问题）

![输入图片说明](/imgs/2024-07-31/RKNFlIYLpqABCfCR.png)

比较一下encoder和decoder
![输入图片说明](/imgs/2024-07-31/zOXFD8Flju3TcQuT.png)
masked是什么意思呢？
自注意力中q只考虑左边的k（包括自己的）相乘加和，因为decoder的输出是一个一个出来的，不能一次性全读到，后面的不知道，只能读前面的

为了不让decoder不停地工作，我们要设置特殊的停止符号
![输入图片说明](/imgs/2024-07-31/HHi6S70f0GJ77ObU.png)
![输入图片说明](/imgs/2024-07-31/7O5gcNNzNZymQeDU.png)
### non-autoregressive（NAT）
VAT以多个begin的符号作为输入，输出与输入数量相同。但在seq2seq的问题里，我们不知道输出的数量，这应该怎么处理呢？
1.train另外一个模型，输入是decoder的输入，输出是decoder输出数量的预测值
2.输入足够多的begin，在输出中读到end后结束，忽略end 之后的内容 
![输入图片说明](/imgs/2024-07-31/wl3Y4chY7W4RVpA9.png)

## encoder-decoder
encoder和decoder之间是如何传递资讯的呢？
![输入图片说明](/imgs/2024-07-31/o6HKGFl0szobhheu.png)
cross attention 有两个输入来自encoder，一个输入来自decoder

cross attention 运作过程
![输入图片说明](/imgs/2024-07-31/OAUbZ0eIs9d3cgIk.png)

## 如何训练
![输入图片说明](/imgs/2024-07-31/ZnT1SlVNoLrgvuNb.png)
理想的输出是one-hot vector，将得到的结果和理想作交叉熵，将交叉熵最小化（类似分类问题）
将所有的交叉熵加和使它最小

在训练的时候，decoder的输入是正确答案
![输入图片说明](/imgs/2024-07-31/3LEwOd5LRhaSBlHy.png)

### 训练seq2seq的tips
#### 复制机制
在聊天机器人中，一些人名或者是很少出现的特殊专有名词直接复制会更接近正确答案
![输入图片说明](/imgs/2024-07-31/UHr0YyYosDQShoQb.png)

做摘要的时候，很多词汇都是从原文中复制出来的
![输入图片说明](/imgs/2024-07-31/YxK4eZPq6vnDwI3a.png)

#### guided attention
有些模型缺失了一些输入对应的输出结果，比如对于语音合成来讲，显然不能接受有的文字没有被读出来，这时候就采用guided attention

guided attention 要求机器按照一定的顺序浏览输入

![输入图片说明](/imgs/2024-07-31/GpG4A9j6qJIoLrNG.png)

#### beam search
![输入图片说明](/imgs/2024-07-31/7V9lsPNxwaEZ5NqG.png)

## optimizing evaluation metrics
![输入图片说明](/imgs/2024-07-31/WtXoSAiNEPK1schj.png)
train的时候是挨个对比，分开来算；test的时候是句与句之间对比
如果硬要在train的时候用句子和句子之间比较，就用RL，把decoder当作agent，把无法optimize的loss function当作reward，硬train一发[doge]

## scheduled sampling
由于在train时给decoder的都是正确的数据，那么在test时一旦出错，很容易给结果造成很大的失误，因此考虑在train时就给一些错误的数据
![输入图片说明](/imgs/2024-07-31/kyC0LJBRv9OLsQQo.png)
![输入图片说明](/imgs/2024-07-31/wmK1bQIrlpXd1rZv.png)

# [Pointer network（指针网络）](https://blog.csdn.net/weixin_40240670/article/details/86483896?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172249622616800213010242%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172249622616800213010242&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-86483896-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=pointer%20network&spm=1018.2226.3001.4187)

> 传统的seq2seq模型是无法解决输出序列的词汇表会随着输入序列长度的改变而改变的问题的，如寻找凸包等。因为对于这类问题，输出往往是输入集合的子集。基于这种特点，作者考虑能不能找到一种结构类似编程语言中的指针，每个指针对应输入序列的一个元素，从而我们可以直接操作输入序列而不需要特意设定输出词汇表。作者给出的答案是指针网络（Pointer Networks）

![输入图片说明](/imgs/2024-08-01/bylhpwRAJVviRAJT.png)
按照attention 的步骤，得到attention的weight，在attention weight 中取argmax，得到的结果就是新的key

应用：文献摘要，（人名地名等的）翻译

# Generative Adversarial Network（GAN，生成式对抗网络）

**生成式网络**
在输入时加入从distribution（例如高斯分布）中随机取样出来的简单分布z，这里的简单是指知道这个分布的式子，因此可以从中取样，这个取样出来的z每次都是不一样的
由于z的影响，输出是一个复杂的分布
![输入图片说明](/imgs/2024-08-01/fRgG7P5cJ6s1EefB.png)

希望输出是一个复杂的分布的目的：我们做的工作需要一些“创造性”，也就是说，希望同样的输入有不同的输出，并且这些输出都是对的，比如画图，对话

## unconditional generation
输入只有z没有x
![输入图片说明](/imgs/2024-08-01/kTbrxeF27IZS60lt.png)
normal distribution是正态分布，也可以是其他的简单分布但是差别不会太大

discriminator（判别器），一个用于判断生成的输出真假的神经网络，输出是数值，数值越大说明越真实
![输入图片说明](/imgs/2024-08-01/BtwsnRxibUKJMc8y.png)
在机器学习中，判别器(discriminator)是一种模型，用于识别输入数据是否属于特定的类别或类别之一。在生成对抗网络(GAN)中判别器是一个模型，用于识别生成器生成的假数据与真实数据之间的区别。判别器和生成器共同构成了GAN，生成器的目标是欺骗判别器，使其无法区分生成的假数据与真实数据，而判别器的目标则是尽可能准确地识别出真实数据和假数据。通过不断的训练，生成器和判别器会相互学习和优化，最终达到生成尽可能真实的假数据的目的。

![输入图片说明](/imgs/2024-08-01/Te8tYcLaw73wOAT2.png)

### 算法
 第一步，先固定generator，训练discriminator，由于输入是随机取样的z，generator，最开始的输出往往不尽人意
 ![输入图片说明](/imgs/2024-08-01/h9hpMF6Te9dgtkjV.png)
训练判别器可以用回归也可以用分类
 
第二步：固定判别器，训练生成器
![输入图片说明](/imgs/2024-08-01/TohvDluYWc3IoHuj.png)
把生成器和判别器看作是接在一起的一个大网络，中间某层隐藏层的输出是生成器的输出，最后几层不能动（固定判别器），希望大网络的输出越大越好

之后反复重复以上两个步骤
## GAN背后的理论
![输入图片说明](/imgs/2024-08-01/CNwH0DA0mx7qWUD7.png)

虽然我们不知道PG和Pdata之间的divergence（分散）如何计算，但是我们可以从PG和Pdata中采样，用采样来估测divergence
![输入图片说明](/imgs/2024-08-01/TXa6iwNGjOjoCnOC.png)
![输入图片说明](/imgs/2024-08-01/6Fqm9yoRlu3OgHRl.png)
我们发现objective function，也就是 argmaxV(D,G) 和divergence 有关，也就是说，越容易把生成数据和真实数据分开，散度越大，反之越小
![输入图片说明](/imgs/2024-08-01/JUmSCZzBSFiB3osr.png)

所以把![输入图片说明](/imgs/2024-08-01/XlSrtnEAxFgChN7V.png)
替换成
![输入图片说明](/imgs/2024-08-01/RTyQZ0L9Ru6rMetY.png)

也可以用不同的divergence
![输入图片说明](/imgs/2024-08-01/AJH8C4DExwOm7p8k.png)

JS divergence 的问题
![输入图片说明](/imgs/2024-08-01/nBhXOhPL9mxYXacv.png)
![输入图片说明](/imgs/2024-08-01/bdj9Bdo1MrB1T7jy.png)

由于JS divergence的loss无法给我们信息，我们换一个衡量两种分布的方式
——Wasserstein distance

## WGAN
用Wasserstein distance来估计Pdata 和 PG 之间的距离叫WGAN
![输入图片说明](/imgs/2024-08-01/t1jbocjOQU5xLhzY.png)
想象有一个推土机，分布P集中在一堆土，分布Q是移土的目的地，把P这堆土移到Q的平均距离就是Wasserstein distance，也就是d
![输入图片说明](/imgs/2024-08-01/r0NJRwVFEfQob4cU.png)

![输入图片说明](/imgs/2024-08-01/lBzDI2lxX8ioi0qc.png)

![输入图片说明](/imgs/2024-08-01/ZL01NJ4gXcwXa5bF.png)
如果限制D足够平滑的话，就不会出现如果generated和real相隔很近的话，一个无限大一个无限小的无效情况

那么如何保证D足够平滑呢？
Lipschitz Function
![输入图片说明](/imgs/2024-08-02/Ocgq1qdbmTtztD5y.png)
### Gradient Penalty
![输入图片说明](/imgs/2024-08-01/NYS1jC3D5Qkdez64.png)

Improved WGAN Gradient Penalty——WGAN GP

限制PG和Pdata之间的区域的梯度小于1，因为我们更新的目的是让PG接近Pdata，他们之间的区域才是有效的
![输入图片说明](/imgs/2024-08-02/U6rXRMZD2NXEeSTb.png)
在Penalty的分布中，让所有D(x) 的梯度小于1
![输入图片说明](/imgs/2024-08-02/6R8uHpz6h3iJxuJW.png)

![输入图片说明](/imgs/2024-08-02/XxadOchTVoaCvjMJ.png)
这种方式的意思是，不仅大于1的要惩罚，小于1的也要惩罚，越接近1越好，但是这种直线也是怪怪的，我们更新的方向应该是沿着红线的gradient

### Spectrum Norm
让每一处的gradient都小于1
![输入图片说明](/imgs/2024-08-02/57nOegAoWFTYZDUe.png)

### 把GAN的算法改成WGAN
GAN:
![输入图片说明](/imgs/2024-08-02/ifn0gP0GdPxHlFUb.png)

WGAN：
![输入图片说明](/imgs/2024-08-02/bXAZ5CF14PmZETyo.png)


除了WGAN，还可以有其他衡量方式——
## LSGAN
![输入图片说明](/imgs/2024-08-02/FbOwkgZ6qkZvaoin.png)
这样就避免了在generated data处因为梯度太小所以训练不起来的情况，这也把它从分类问题变成了回归问题

## Energy-based GAN(EBGAN)
在辨别器中使用autoencoder，使用重构误差作为衡量标准
![输入图片说明](/imgs/2024-08-02/pc3lR64CwXzqZv2K.png)
![输入图片说明](/imgs/2024-08-02/r3xWzsDM61V0bJxW.png)
不能让generated 的reconstructed error太小，只要小于m就可以了


## GAN的训练技巧
如果判别器和生成器中的任意一个不能再更新，另一个也会受到影响停止更新，因此GAN非常难训练，一些小技巧也应运而生

GAN的训练难度最主要在于生成器的训练
在某些情况下，因为生成器产生的一点点小小的变化不会影响分布的最大值，也就不会影响结果，因此不能用gradient descent，以生成文字为例
![输入图片说明](/imgs/2024-08-01/0tPNGNBwse1bgDqk.png)

在gradient descent不能用时，可以用RL硬train一发，但是RL很难训练，GAN也很难训练
![输入图片说明](/imgs/2024-08-01/ZkDYNeJsk2qzSd7H.png)

## 怎么评估生成器的好坏
用影像分类系统
影像分类系统输入是一张图片，输出是一个几率分布，几率分布越集中产生的图片可能更好

### 衡量生成器的多样性
但是可能出现一个问题——mode collapese
生成器生成的某些图片可以骗过判别器，因此重复生成这些图片或者只有很小差异的图片，缺失多样性
![输入图片说明](/imgs/2024-08-01/UeYihunY0ZA30oEU.png)
这是一个比较容易被发现的问题，还有其他不容易被发现的问题

mode dropping
产生出来的资料可能只有真实资料的一部分
![输入图片说明](/imgs/2024-08-01/emr6mxdQuTquDweD.png)

#### inception score
![输入图片说明](/imgs/2024-08-01/p2wL72uQBUWrXahN.png)
如果最后产生的平均分布非常集中，那么多样性不够


如果最后产生的平均分布非常平坦，那么多样性很好
![输入图片说明](/imgs/2024-08-01/c5IXQhGqOI8QvfuC.png)

#### FID
取出在softmax之前的hidden layer的输出来代表图片
![输入图片说明](/imgs/2024-08-01/meP3ZGXJ7VH5BHQS.png)

#### 用训练资料的坏生成器
![输入图片说明](/imgs/2024-08-01/WJqH6wXJwsHmeefS.png)
![输入图片说明](/imgs/2024-08-01/UuDIK5FfLSvo14Jx.png)

## conditional generation
![输入图片说明](/imgs/2024-08-01/ryhgIdHFZX5R6IL4.png)

![输入图片说明](/imgs/2024-08-01/dkL1FJfeNnPGWMct.png)
不能完全照搬unconditional generation的模式，因为这样会导致判别器不看x的输入
![输入图片说明](/imgs/2024-08-01/7ieQI4Q6SPbf0SL7.png)

更多应用
![输入图片说明](/imgs/2024-08-01/efUByuXA55gwiSJX.png)

![输入图片说明](/imgs/2024-08-01/4cHtLSyzhWgClmSJ.png)
GAN因为太有想象力所以要加入监督模式使它接近正确答案

![输入图片说明](/imgs/2024-08-01/AEe8TxOd7hIhFJmy.png)


## learning from unpaired data
也就是非监督性的学习
![输入图片说明](/imgs/2024-08-01/XWXqdhHHP2fFJNmP.png)
![输入图片说明](/imgs/2024-08-01/oHtn9ffxeVTyw2Fq.png)

![输入图片说明](/imgs/2024-08-01/SgpmaPrOQpfnZUAV.png)

![输入图片说明](/imgs/2024-08-01/ILEpNbd2DDvgGDAP.png)
把原来从正态分布中取样换成从X domain 中取样，有一个分辨器可以分辨输出是否为Y domain，但是还缺失了输出和输入的相关性

### Cycle GAN
经过两次转换之间的输入和输出越接近越好
![输入图片说明](/imgs/2024-08-01/YKLeHUA05VBps2BT.png)

也可以反向
![输入图片说明](/imgs/2024-08-01/pkfhvKYhaN9iym3c.png)

其他应用
语义转换
![输入图片说明](/imgs/2024-08-01/PYoAWY5C2ElnSJN2.png)
![输入图片说明](/imgs/2024-08-01/ug92Cpw1zpdKftmG.png)

# GAN理论
在我们需要生成的对象的高维空间中（比如图像），只有很少一部分是贴合我们的要求（比如生成人脸，图像的高维空间中只有很少一部分是像人脸的）
![输入图片说明](/imgs/2024-08-02/Vy68cZlWOMkdlrBc.png)
GAN需要做的事情就是找出贴合我们要求那部分的分布Pdata

在GAN之前，用的是极大似然值，已知简单分布 PG 的式子，希望 从 Pdata 中取出的样本，如果用PG 来产生的话，likelihood 越大越好 
![输入图片说明](/imgs/2024-08-02/QJWprIvZhALRxNpU.png)
![输入图片说明](/imgs/2024-08-02/5kNOLWw5z7HJzOBA.png)

由于正态分布有很多限制，我们想要更普用的分布PG
![输入图片说明](/imgs/2024-08-02/8cfnGZ8epNArA7Kn.png)
PG 和 Pdata 的式子我们都不知道，因此不能直接算出divergence

GAN的神奇之处在于它可以通过辨别器来衡量两个分布之间的divergence
![输入图片说明](/imgs/2024-08-02/xUkKG8ttXrmJmaiB.png)
![输入图片说明](/imgs/2024-08-02/KAcsdMO1HEbbh3uL.png)
![输入图片说明](/imgs/2024-08-02/hazhHgjDhqRyssLi.png)
两类容易分辨可以很轻易地让V(D,G) 很大，说明他们的divergence很大

======================================================

MATH WARNING
![输入图片说明](/imgs/2024-08-02/gahb8TiBR860tnPq.png)
![输入图片说明](/imgs/2024-08-02/V7dYibKoZs3q1QIk.png)
![输入图片说明](/imgs/2024-08-02/JOiShUbu8d3MP12u.png)
![输入图片说明](/imgs/2024-08-02/Qx3PTlF3vn6PUgEW.png)

======================================================

![输入图片说明](/imgs/2024-08-02/8SVNSgHAIEuV5Yl0.png)
![输入图片说明](/imgs/2024-08-02/wrFi3qBAdJpd1ACM.png)
G3是最好的结果

![输入图片说明](/imgs/2024-08-02/C9YNMSMs8BufXbH6.png)

![输入图片说明](/imgs/2024-08-02/qIzGIKp2DquQdXu3.png)
![输入图片说明](/imgs/2024-08-02/B6okl3c4EcOvnjVL.png)

![输入图片说明](/imgs/2024-08-02/rQP5zQUMDrnV7mLa.png)
![输入图片说明](/imgs/2024-08-02/eTw2kNwy3LgsvisK.png)

![输入图片说明](/imgs/2024-08-02/ifn0gP0GdPxHlFUb.png)
![输入图片说明](/imgs/2024-08-02/pwIsQtOsP6ITZl1f.png)

直觉上，
![输入图片说明](/imgs/2024-08-02/TGPITelQyPn1n9xL.png)

# Flow-based Generative Model
![输入图片说明](/imgs/2024-08-05/p9mhyLmHDXZwJzmj.png)
因为都是概率分布，面积都是1

![输入图片说明](/imgs/2024-08-05/IMqxumra6MZU0ZPM.png)
![输入图片说明](/imgs/2024-08-05/Dm2GsUMfiZmWZWIA.png)

————————————————————————————————————————————————————————
![输入图片说明](/imgs/2024-08-05/vsZi5pSHYCyvIokp.png)
为了确保generator G可逆，要让z和x的维度相同，因为要计算雅戈比行列式，我们希望通过限制G来减少计算量

被限制之后的G会能力减弱，因此不妨多用几个G
![输入图片说明](/imgs/2024-08-05/6QisjD2LQfRRCBLy.png)
![输入图片说明](/imgs/2024-08-05/4wrO3YNeAADVVrS9.png)
![输入图片说明](/imgs/2024-08-05/IdqNsbVSQ3L3isZY.png)


# Self-supervised learning（自监督学习）
莫名其妙的与芝麻街人名有关的自监督学习模型
![输入图片说明](/imgs/2024-08-02/JIH9oiIW9XHW1JMK.png)
有点黑色幽默了属于是


self-supervised 是一种无监督学习，它把输入的 x 分为两部分x' 和x'' 把x' 作为输入，x''作为label
![输入图片说明](/imgs/2024-08-02/I6tXdcs5LyW9f7X6.png)

## Pre-train model
可以把每个token用embedding vector 表示，embedding vector要含有语义，意思相近的token要有比较相近的embedding
contextualized word embedding，在看完整个句子后才得到embedding vector
![输入图片说明](/imgs/2024-08-02/K2RNUg2qcJVmQhi7.png)

或者使用有权重的特征
![输入图片说明](/imgs/2024-08-03/8YJlY9XDiZeEcIUn.png)


## bert模型
bert训练——
**masking**
以文字为例，随机把文字中的一些部分“盖住”
“盖住”的方式：1.用特殊的符号替代(token是处理文字的单位，可以是一个汉字，一个字母，一个单词等等）2.随机用一个别的token来替换
![输入图片说明](/imgs/2024-08-02/9UMEmSN8lMNwKao9.png)

另外的训练方法——
next sentence prediction（但是不是很有用）
![输入图片说明](/imgs/2024-08-02/dAuVTTLXGAuuSuS7.png)
让bert输出句子1和2是不是上下文（Yes/No），但是不能很好地训练bert（可能是因为这个任务太简单了）
因此后面又提出了让bert判断句1和2的顺序，这个比较有效

==============
怎样pre-train一个seq2seq的模型呢？
![输入图片说明](/imgs/2024-08-02/h3fk6xmiMsB3dqCY.png)
把输入做一些扰动，希望decoder的输出可以接近扰动前的输入

如何扰动？
“盖住”、删除、打乱顺序，或者把词汇顺序旋转等等
打乱顺序的表现不太好
![输入图片说明](/imgs/2024-08-03/hViuMeuRRwj8IsZB.png)

UniLM：既是encoder，又是decoder，还是seq2seq model
![输入图片说明](/imgs/2024-08-03/KTvfe0oV7F2f4NJf.png)
![输入图片说明](/imgs/2024-08-03/NIDAnWvL3SIWK9j4.png)
这个model同时进行了3种训练





只通过这两种方式训练的bert却拥有解决各式各样任务（下游的任务）的能力，这叫做fine-tune（微调）
![输入图片说明](/imgs/2024-08-02/ZEisKNWdSAZvOpQX.png)

测试像bert这样可以用于多个不同任务的模型（像是胚胎干细胞可以分化成不同细胞）的任务集（有很多任务用于测试）中，有一个最知名的标杆叫做GLUE（general language understanding evaluation），涵盖九个任务，微调后得到模型，计算它们的平均正确率![输入图片说明](/imgs/2024-08-02/PpY9FXAoaKjfuANu.png)

### bert是怎么被使用的呢？
举例：
![输入图片说明](/imgs/2024-08-02/VGnBjv5BpCYX1RQW.png)
最重要的是BERT已经提前训练好了所以会有好的表现，线性变换的矩阵都是随机初始化的

### bert的工作原理
![输入图片说明](/imgs/2024-08-02/sUYISnHGL4IwsrjE.png)

bert 可以学到字的不同意思，这可能是因为它同时学习了上下文
![输入图片说明](/imgs/2024-08-02/Mpxi6RU3pT4tx63v.png)

### multi-lingual bert（多语言bert）
![输入图片说明](/imgs/2024-08-02/PWdt0nt6zOeAPzBE.png)
预训练只做了填空，但是做语义理解的问答得到的结果却非常好
有一种猜测是觉得对于模型来讲，它只看实际的意思，语种对它来说影响不大，也就是说，不同语种表达相同意思的词的向量差距不大
![输入图片说明](/imgs/2024-08-02/ijjEDpYtaUOaKJR8.png)



## GPT模型
训练
![输入图片说明](/imgs/2024-08-02/kr7TSCONF80LxnkN.png)
像是不会看到下一个词的transformer的decoder

GPT最厉害的地方在于它可以生成


GPT的任务：不用像BERT需要微调就可以完成各种任务
![输入图片说明](/imgs/2024-08-02/i99zLcT6g7ewX5yO.png)
给它问题的描述，给它几个范例，就希望它可以做到同样的事情

![输入图片说明](/imgs/2024-08-02/ivpEO1RBjxzL4gUb.png)

## 如何微调
### NLP的任务分类
![输入图片说明](/imgs/2024-08-03/knOnxv8dcPYEeWkE.png)
怎么把pretrain model加上一些东西后，让它可以处理NLP的各种任务

如何处理多个句子的input？
![输入图片说明](/imgs/2024-08-03/7CbU2dbbLAUZVbAd.png)
用[SEP]把多个句子间隔开，在训练模型时要让模型习得[SEP]的意思

输入的[CLS]是要让后面的token产生**跟整个句子有关**的embedding
![输入图片说明](/imgs/2024-08-03/JYXme4jNXLMibAb5.png)

![输入图片说明](/imgs/2024-08-03/D2TGBdVUyBweecQy.png)
![输入图片说明](/imgs/2024-08-03/jREhaLKayCPChwj1.png)
用橙色向量侦测起始位置，用橙色向量和得到的每个token的embedding做点积再做softmax（或者也可以采用其他更复杂的方式得到分布），最大的所在的位置是起始位置
![输入图片说明](/imgs/2024-08-03/mikkCDw0Eqk0bM4p.png)
用蓝色向量侦测结束位置
![输入图片说明](/imgs/2024-08-03/F1RNRIZaBpqa91gj.png)

![输入图片说明](/imgs/2024-08-03/lGKTOJgtAEJfyrLr.png)
![输入图片说明](/imgs/2024-08-03/jZhgT0Nu6uRmnWJm.png)

### 微调的方式
1.固定pre-trained model，作为feature extractor（特征提取器）
2.除了调整task-specific还会调整pre-trained，相当于将两者拼在一起看作一个巨大的model来解决下游任务，不过因为pre-trained model并不是随机初始化的（之前已经做了填空题了）所以不会那么容易overfitting
![输入图片说明](/imgs/2024-08-03/rmzFXE9tBITDYcaY.png)
第二种的表现往往会好一些

但是对于第二种而言，每个任务都调实在是太巨大了，因此引出了adaptor的概念
![输入图片说明](/imgs/2024-08-03/tWkSzzSxSxaAlPBE.png)

也就是说，在调整pre-trained model时，只调整它的一部分就好了
![输入图片说明](/imgs/2024-08-03/ubAF8b5MVy4Ph7df.png)
现在要存的就是调整前的model和三个adaptor的参数

pre-train时是没有adapter的，adapter是准备微调的时候才插进去，而且微调时，pre-trained model只调adapter的参数
![输入图片说明](/imgs/2024-08-03/NhfhmPu21TxWVoKr.png)

## 如何Pre-train
![输入图片说明](/imgs/2024-08-03/PfeVEkbhpkl2TtS2.png)
不能把下一个输入告诉它，不然就相当于直接告诉它正确答案了，达不到训练的目的

训练从w到h的有很多模型，比如LSTM、self-attention等等，但是如果要用self-attention做这件事，就要给它一些限制，因为不能把下一个输入告诉它
![输入图片说明](/imgs/2024-08-03/8XVODtWJvfGooozL.png)
就像上图中的表格中，只有涂色位置是可以attend的，w1只能attend w1，w2可以attend w1和w2

BERT在pretrain的时候是**同时**考虑了左边的文本和右边的文本
![输入图片说明](/imgs/2024-08-03/6tSegrQgVJiVCpqD.png)
因为BERT掩盖了某个位置上的信息，所以它不怕模型看上下文，它的self-attention是没有任何限制的

### masking input
之前讲的masking就是随机选token来掩盖，但是这种方式比较简单，机器很容易就可以学习到
为了pretrain得更好，我们要采用更复杂的mask的方式
![输入图片说明](/imgs/2024-08-03/hoi61N7YHSQb13Kr.png)


SpanBert一次性盖一排
![输入图片说明](/imgs/2024-08-03/ewfzDxTcba5BrAZy.png)
![输入图片说明](/imgs/2024-08-03/LKaKBSksGXtcQmqq.png)

XLNet
解决了一些有些词会被一起盖住从而让这两个词分开时不能被精准预测，把输入顺序打乱然后预测后面的，也就是说，用各种各样的资讯去预测一个token，这样它会更有关联性
![输入图片说明](/imgs/2024-08-03/ofb4ACzTfaOuzUAO.png)

与原来的BERT相比，XLNet只随机地选取一部分用来做填空题；并且XLNet不会给模型看到mask token，但是会告诉模型预测哪个位置的token（positional information）
![输入图片说明](/imgs/2024-08-03/SVVeIgrMZbeICOnB.png)


![输入图片说明](/imgs/2024-08-03/JltQq0weW6oG1t5Z.png)


ELECTRA
将句子中的词置换为没有造成语法错误但是语义上有些奇怪的词，模型判断每个词是否被置换了，比如对于句子：the chef cooked the meal
![输入图片说明](/imgs/2024-08-03/x4BXFr6HEQmrxM68.png)
有一个小BERT来填词，使这个错误并不是很明显但又确实存在
 ![输入图片说明](/imgs/2024-08-03/St9BHjlwDGCWhT9y.png)
 
### sentence-level
整个句子生成一个embedding

skip thought：用输入的句子预测它的下一个句子，如果两个句子的下一个句子很接近，就让他们的embedding接近，但是生成的运算量比较大
quick thought：让相近的两个句子的embedding接近
![输入图片说明](/imgs/2024-08-03/MZE3n1ZfGcEHAlsc.png)
![输入图片说明](/imgs/2024-08-03/OjQ07K84sZOHOYiN.png)

# Aauto-encoder
Encoder：输入是高维度向量，输出是低维度向量（Dimension reduction）
Decoder：把压缩后的向量还原成图像。
通常它们使用的都是神经网络
![输入图片说明](/imgs/2024-08-03/60cDr6KcGSUu3KKf.png)
整个reconstruction的过程就是auto-encoder，这个过程不需要label data，所以是一种无监督的学习算法

## auto-encoder工作原理
以图像为例，虽然图像的维度非常高，但是在高维空间中只有一小部分是图像，也就是说，图像能做的变化其实是有限的，我们可以用更低维度的向量来表示这些变化
![输入图片说明](/imgs/2024-08-03/hJq0vsA17wmqdCUV.png)

## De-noising Auto-encoder
输入有杂讯的AE，使decoder的输出尽量接近添加杂讯前的向量
![输入图片说明](/imgs/2024-08-03/FP4eNSyNfDgXj08t.png)
![输入图片说明](/imgs/2024-08-03/XdKwBEm2fqnQW3Yr.png)

## Feature Disentangle
Feature Disentangle（特征分解）把一个输入模型的很长的向量分解开，知道哪些维度是代表哪个特征的
![输入图片说明](/imgs/2024-08-03/kIxMDDuud77w5ouC.png)

## Discrete Latent Representation
![输入图片说明](/imgs/2024-08-03/9anv8JqDZWkfjSnY.png)

对于一排学习出来的向量（也就是不确定的参数），把从encoder中学习出来的向量和这些向量集算相似度，选出来最相似的一个作为decoder的输出
![输入图片说明](/imgs/2024-08-03/afRRN7WqHdLSJws9.png)

输入不用向量用文本，embedding也让它是文本
![输入图片说明](/imgs/2024-08-03/a2azk13HHECW2ro9.png)
我们想要embedding是文章的摘要，但是发现虽然decoder可以还原文章，但是中间生成的东西是我们看不懂的，因此用了GAN中discriminator的概念
![输入图片说明](/imgs/2024-08-03/em5O5EQ8fJsKY6tM.png)

## 更多应用
1.作为generator
![输入图片说明](/imgs/2024-08-03/831kwq8wAibRVsf7.png)

2.压缩
![输入图片说明](/imgs/2024-08-03/xxi6LCtqU4hlnQZE.png)
输出会失真

3.异常检测
![输入图片说明](/imgs/2024-08-03/6EME7XwYfcXUHqb7.png)
![输入图片说明](/imgs/2024-08-03/Ol7TjDKz82D3IypB.png)
可以看作二元分类问题吗？
通常这种问题是有很多正常资料但是很少异常资料，所以它不是一个一般的分类问题

![输入图片说明](/imgs/2024-08-03/apv8IpfCzxt9CkTW.png)
根据reconstruction的好坏来判断异常

# Variational AutoEncoder（变分自编码，VAE）
![输入图片说明](/imgs/2024-08-05/BkRgAQyJ92535iiY.png)

直觉的感受为什么要用VAE
![输入图片说明](/imgs/2024-08-05/MX2zlXCBlArhpFhG.png)
VAE会给code 加上一段noise，因此VAE的decoder对于那一段的code都返回同一张图像，而介于两段噪音之间的（既要像图一又要像图二）就会是介于两张图之间的样子

————————————————————————————————————————————————
![输入图片说明](/imgs/2024-08-05/uo2fOPjbnDAsxxTx.png)
如果只是单纯让reconstruction error最小，机器可能会直接让noise为0，因此要对variance做一些限制，让它不能太小
![输入图片说明](/imgs/2024-08-05/dQDyWhNp5yYFHGyU.png)

## Gaussian Mixture Model
![输入图片说明](/imgs/2024-08-05/TDqqqVkts5sr6BZG.png)P(m)是weight 

![输入图片说明](/imgs/2024-08-05/eZO38v540MnfDWqe.png)

![输入图片说明](/imgs/2024-08-05/bMhKp8jkkbKPtOgW.png)

![输入图片说明](/imgs/2024-08-05/XQatbA9uLxOpAqj0.png)
划红线的式子是KL divergence，q(z|x)表示任意分布，不会影响P(x)

![输入图片说明](/imgs/2024-08-05/ZNLRd6htQQrkXUZT.png)

![输入图片说明](/imgs/2024-08-05/ZorFe5mEAm2z4Qwv.png)

![输入图片说明](/imgs/2024-08-05/jipHrCZQUHNjZfQb.png)

# [PCA](https://blog.csdn.net/zs_id/article/details/135316703?ops_request_misc=&request_id=&biz_id=102&utm_term=PCA&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-135316703.142%5Ev100%5Epc_search_result_base2&spm=1018.2226.3001.4187)
## Clustering（聚类）
Clustering的方法
1.K-means
![输入图片说明](/imgs/2024-08-05/8FJUfnAk6ATy1NZE.png)
ci从X中随机取样的原因：这样可以保证X中总是会有一些项和ci接近

2.Hierarchical Agglomerative Clustering(HAC)
第一步：build tree
把所有vector 两两计算相似度，把最相似的两个平均起来得到新的vector，把新的vector和之前除去了最相似的两个vector剩下的vector两两计算相似度，再通过一样的方法得到新vector
第二步：划定分界线
根据划定的分界线来分类
![输入图片说明](/imgs/2024-08-05/qH9SQ28QGChin2Oa.png)
![输入图片说明](/imgs/2024-08-05/lUufOPSgqj2qMQfg.png)
![输入图片说明](/imgs/2024-08-05/quMkeki3IhR26aoW.png)
————————————————————————————————————————————
K-means要决定K的值，HAC要决定分界线的位置

## Dimension Reduction
以图像为例，虽然图像的维度非常高，但是在高维空间中只有一小部分是图像，也就是说，图像能做的变化其实是有限的，我们可以用更低维度的向量来表示这些变化
Dimension Reduction的方法：
1.Feature selection
可以去掉一些维度
![输入图片说明](/imgs/2024-08-05/HvLuHHIRZ7adaA8e.png)

2.PCA（Principle component analysis）
找出 z = Wx 的 W ，z是dimention reduction 的结果，x是原来的vector
先降低到一维的情况
![输入图片说明](/imgs/2024-08-05/sCEL8Lz4b3o5Prl3.png)
![输入图片说明](/imgs/2024-08-05/hi2pah0lCXSCY9R4.png)
w1、w2正交

![输入图片说明](/imgs/2024-08-05/RAQttZG8HHdi1Jfr.png)
![输入图片说明](/imgs/2024-08-05/jSxCyTjYd8UDB9t7.png)
![输入图片说明](/imgs/2024-08-05/uucZxUeKb8bSXeZy.png)
 
 PCA-去相关性
![输入图片说明](/imgs/2024-08-05/264EZ8eC3LNqJHnl.png)
对角型矩阵

总结：w1,w2……依次取协方差矩阵S对应的最大，第二大……的特征向量，S=Cov(x)，即
![输入图片说明](/imgs/2024-08-05/zttKMQBWLqdLrq8X.png)

## Another Point of PCA
![输入图片说明](/imgs/2024-08-05/1KrZ0mg2aWX9xsoG.png)
![输入图片说明](/imgs/2024-08-05/Jj0oh4EEcYDKXXyt.png)
c的上标是x的次序，下标是一个式子中c的次序
![输入图片说明](/imgs/2024-08-05/lymsnaFjcuaZ6i9j.png)
![输入图片说明](/imgs/2024-08-05/KCm91scaxjyAMquJ.png)

## PCA的弱点
![输入图片说明](/imgs/2024-08-05/J3v6opCiFMnJr0Yz.png)
unsupervised：假如在二维空间上其实有蓝色、橙色两类，但被降到一维时，映射到上面那张图的红色箭头方向上，就会分不开这两类，这种时候或许需要LDA，但是LDA是监督学习
Linear：线性的特性让PCA在降维时可能面临特征会混杂在一起的情况

## 实际应用
要决定有多少个principle components
可以使用算比率的方法
![输入图片说明](/imgs/2024-08-05/HzGiFLiJaL1g56ZF.png)

![输入图片说明](/imgs/2024-08-05/IhtiNu7GevkhXJrE.png)
具体分析意义

![输入图片说明](/imgs/2024-08-05/2eAYQgIQuL5ArhZz.png)

![输入图片说明](/imgs/2024-08-05/qrgenJO4QUaxOrbK.png)

![输入图片说明](/imgs/2024-08-05/5xV4Y50mJwBCo0yC.png)

PCA可正可负，可以是一个很复杂的东西减去其他的一些东西
NMF就让系数和component都是非负的，这样得出来的component都会更接近于图像的一部分
![输入图片说明](/imgs/2024-08-05/bGFlb8G1aatb8k2Y.png)
![输入图片说明](/imgs/2024-08-05/TBm8wa8B1aX7Dlso.png)

# Explainable ML
我们需要机器解释它们做出每种行为的理由

解释的分类：![输入图片说明](/imgs/2024-08-05/LxWgVJPlXqeh8kGJ.png)

## 1.local explanation
![输入图片说明](/imgs/2024-08-05/uTEooMHgrnUw2KTH.png)
可以把图片的一部分遮住，看看会不会对结果产生很大的影响

或者采用saliency map的技术
### saliency map

![输入图片说明](/imgs/2024-08-05/gbrACr7Aa1k1vPKp.png)
浅色的部分是偏导值较大的部分，说明它们的变化会引起较大的Loss的变化，也就是说，这些是判断图片的关键地方
——————————————————————————————————————————————————————
saliency map 的限制
（1）noisy gradient，除了一些人类认为重要的地方，机器可能还会认为其他地方对图像的判别重要，这时候可以采用smooothgrad，就是随机地添加噪音，得到所有的saliency map 后再把它们做平均
![输入图片说明](/imgs/2024-08-05/2Dg2qhVNjorjNu1i.png)

（2）gradient saturation（饱和）
在到达某个临界点后，当某个特征更显著时，判断图像属于某个类别的可能性不会继续增加，这时候做偏微分是约等于0的，有可能会因此得出这个特征不重要的结论
![输入图片说明](/imgs/2024-08-05/DxvXbO1zdivsmv2S.png)

### 探究network是如何处理数据的
人眼来看
![输入图片说明](/imgs/2024-08-05/anjE8jzrjFonANO7.png)

探针来探测中间某些部分的结果，一般探针用的是分类器，但是要注意探针要训练好，如果训练得不好也会影响结果
![输入图片说明](/imgs/2024-08-05/CFCMEwK2c7E4ikPw.png)

## 2.global explanation
![输入图片说明](/imgs/2024-08-05/UKrR5ZsnHAWDzegZ.png)
对于一张图片，如果filter 1得到的feature map 的值较大，说明这张图上有较多 filter 1可以侦测到的特征，但是如果没有这张图，我们又想知道filter 1侦测哪些特征，我们就要自己创造一张图包含这些特征
那么怎么创造这张图呢？

把这张图当作未知参数的矩阵X，把X当作已经训练好的模型的输入，让模型输出的feature map里面的值越大越好，用到gradient ascent的方法（原理与gradient descent相同，只是让最后的结果最大），通过得到的X*的特征得到对应的filter是在侦测什么特征
![输入图片说明](/imgs/2024-08-05/ICfIBhQUOoxDxEWj.png)

事实上，以手写数字为例，得到的图片对于人来讲只是一些杂讯，虽然对机器来讲这些图片是非常关键的，即使是拿最后输出的结果来分析
![输入图片说明](/imgs/2024-08-05/IrtNsDdaYtDoCUCw.png)

那么想要结果看起来像人眼中的数字应该怎么做呢？给X更多的限制
![输入图片说明](/imgs/2024-08-05/55epq2kk1LWpczWC.png)
此次R(X)的意思是希望白色的点越少越好

除了给限制以外，也可以用generator
![输入图片说明](/imgs/2024-08-05/liw4oYNRIQ2Md0yj.png)

## 3.其他
用简单的模型去模仿复杂的模型，如果可以模仿，再去分析简单的模型
![输入图片说明](/imgs/2024-08-05/AqET5WTuvQG3NqVo.png)

# Adversarial Attack
![输入图片说明](/imgs/2024-08-05/emRgFVMtFhF1N9kj.png)

## White Box Attack
已知参数才能进行的攻击

### 什么是attack
![输入图片说明](/imgs/2024-08-05/147gScXPnr5Ts8hA.png)
加入一个人肉眼看不到的杂讯，使network 的输出改变
attack分为targeted和non-targeted

### 怎样attack
下图分别是得到targeted和non-targeted的attack的方式
![输入图片说明](/imgs/2024-08-05/xKe6LjU7Da14AbEy.png)

如何计算两图之间的距离？
![输入图片说明](/imgs/2024-08-06/j2Rxjg1mAMlVZrdK.png)
右边的图的L2-norm是一样的，但是上面的图是每个pixel都发生了微小的改变，下面的图是只有绿色那个pixel发生了较大的改变，而人眼可以察觉到下面那张图发生的改变，因此得出L-infinity的方法可能更接近于人眼的观察，因此让L-infinity小的效果才是更好的

如果没有对d(x0,x)的限制，我们可以采用类似于gradient descent的方法来做，只是更新的不是参数，而是输入（也就是被attack后的输入），而且是以x0作为起点（因为我们希望x可以接近x0）
![输入图片说明](/imgs/2024-08-06/5M51enqI4JamVSVS.png)
接下来加上d(x0,x)≤ε 的限制
![输入图片说明](/imgs/2024-08-06/CmAd6SbLQUseSoNA.png)
如果超出d(x0,x)≤ε 的范围，就把它拉回这个范围

FGSM
![输入图片说明](/imgs/2024-08-06/GQXecdV8IS1a3shp.png)
Learning rate取ε，这样更新的时候就不会脱离出d(x0,x)≤ε 的范围

可以多update的几次，但是可能会出界，这时候拉回界内就可以了
![输入图片说明](/imgs/2024-08-06/xyXAn3D2Ldf6Ccqs.png)

## Black Box Attack
不知道要攻击的模型的参数（黑盒子）

假如知道要攻击的模型所用的训练资料，用这个训练资料训练一个模仿我们要攻击的对象的模型（Network Proxy），把攻击Proxynetwork成功的图像用去攻击要攻击的对象，也许也能成功
![输入图片说明](/imgs/2024-08-06/bE8AVrrLAsxjlvnx.png)

如果完全没有训练模型，以影像辨识系统为例，可以输入很多影像，得到输出，再用这些对应的输入输出训练模型，有可能可以训练出类似的模型

除了图像，语音处理、NLP等也会被攻击

## 发生在现实世界的攻击
比如一个人带上一副特殊的眼镜后，就会被人脸辨识系统辨认为另外一个人
![输入图片说明](/imgs/2024-08-06/8w9JwAkkDLY3Cggf.png)
从多个角度来看人脸辨识系统都会出错
考虑了摄像头的解析度，确定微小的杂讯是可以被摄像头捕捉到的

## 在训练阶段就展开攻击
![输入图片说明](/imgs/2024-08-06/elkSIpBKCnOpTylc.png)
要小心一些资料集中含有被开后门的图片

## 防御
### 被动防御
在模型前加一个“盾牌”filter，例如把图片模糊化一点
![输入图片说明](/imgs/2024-08-06/vlKcyByVuvQ57321.png)

但是也不能太模糊了，不然信心分数会下降得比较多
![输入图片说明](/imgs/2024-08-06/ZZA81QRFnhLzcIgN.png)

除了模糊化，还有很多其他的被动防御的方法
比如把图像压缩，图像压缩失真后可能会让攻击信号失去威力
或者用generator生成和原来的影像相似的图，因为generator没有学习过杂讯，可以生成出和原来的图片接近的图片并且没有杂讯
![输入图片说明](/imgs/2024-08-06/aWAidpqEEnrvElD7.png)

如果攻击者知道了被动防御的方法，就可以把被动防御也纳入攻击范围，这时候被动防御就不会很有效了，所以我们给被动防御加上随机性
![输入图片说明](/imgs/2024-08-06/glmMYJjxpWdlS8IN.png)

### 主动防御
![输入图片说明](/imgs/2024-08-06/EbRLghOZUzbYvBGm.png)
这种方式不一定能应付新的攻击方式，同时需要非常大的运算资源

# 领域自适应（domain adaptation）
Domain shift：
1.训练资料和测试资料输入的分布不同（比如辨别手写数字，训练资料是黑白的，测试资料是彩色的）
2.训练资料和测试资料输出的分布不同
3.训练资料和测试资料中输入和输出的关系变了
![输入图片说明](/imgs/2024-08-07/tWpIWL3BXxP3IHvy.png)
在这节课程中主要聚焦于第一种情况

Domain Adaptation：
1.有 target domain 的资料也有标注，但是量很少
这时候可以用这些标注的资料来微调在source domain上训练出来的模型，但是注意不要update太多次，避免overfitting
![输入图片说明](/imgs/2024-08-07/vK92hpiLA38VQMna.png)

2.在target domain上有大量的资料但是没有label
solution
![输入图片说明](/imgs/2024-08-07/WaXihXvethx15Duy.png)

以手写数字辨识为例，把classifier 分为两部分，一部分是feature extractor ，另一部分是Label Predictor 
如何使用没有标记的资料呢？
让没有标记的资料的分布接近于source domain
![输入图片说明](/imgs/2024-08-07/kdue3vvCULha2xWa.png)
（让蓝色的点跟红色的点的分布分不出差异）

![输入图片说明](/imgs/2024-08-07/Dcj3zdML4EiZVa9z.png)
feature extractor要提取出target domain和source domain的共同特征来欺骗domain classifier（二元分类器，分辨domain是target domain 还是 source domain）——>类似于GAN
L是source domain 通过feature extractor再通过label predictor输出的结果和label之间的Loss
Ld是二元分类的loss

即要保持最终结果的正确（辨别图片中的数字是正确的），又要骗过domain classifer，因此feature extractor 要有适当的权重
比如对于比较像的1和7，如果骗过domain classifer占的比重较大，可能会导致不能正确的分辨1和7

feature extractor有可能一直输出0来欺骗domain classifier吗？
因为label predictor需要根据feature extractor来输出正确的结果（比如说图片中的数字是几），所以feature extractor不能只输出0

![输入图片说明](/imgs/2024-08-07/uEVnTzMOYPxzYwEB.png)
如果在source domain上有不同的类别，我们希望target domain可以远离source domain类与类之间的分界线
![输入图片说明](/imgs/2024-08-07/a9dS9FTjrZZfQpsY.png)

# 神经网络压缩
神经网络压缩：用在资源有限的环境下（比如智能手表上），减少大模型的参数，但是功能和原来接近
为什么不在算力更充足的环境下运算呢？有延迟、要保护隐私

![输入图片说明](/imgs/2024-08-07/0VkZHMYzvoGNGj2R.png)
黄色方框中的large和smaller指的是模型的大小

在实践上，如果以参数为单位来精简网络，会导致神经网络不规则，同一层神经元与其他层神经元的相连方式不同，导致在运算时不好操作，矩阵运算不好运算，就算为了对称性把参数补0，实际上也需要memory，也不会加速运算
![输入图片说明](/imgs/2024-08-07/UPafVvuNkeD4KWmL.png)
![输入图片说明](/imgs/2024-08-07/WW9MfuNFCowT8A53.png)
可以看出虽然减少了接近95%的参数但是实际的运算速度甚至变慢了一些（紫色折线代表减少的参数所占百分比，看右边，柱状图代表相比原来的速度，看左边，大于1说明有加速）

## Neuron pruning （精简神经元）
减少神经元，结构仍是对称的，只要在实做pytorch时减少层输入输出的维度就可以了
![输入图片说明](/imgs/2024-08-07/sEfMPHXDanY4AxSE.png)

那么，为什么是把大的网络精简为小的，而不是把小的调整成大的呢？
大的网络更容易被成功地训练

为什么大的网络更好训练呢？
大乐透假说——
![输入图片说明](/imgs/2024-08-07/3OwdDv63pdHxcfHz.png)
大的网络由很多小的副网络组成，只要其中一个副网络得到比较好的结果，大的网络就可以得到比较好的结果
![输入图片说明](/imgs/2024-08-07/jEaV2HOZq40MVxsd.png)
对于大的网络最后留下来的那些神经元，绿色的是完全随机初始化的，训练不出好的结果，红色的是完全复制之前大网络的初始化参数的，就可以成功训练

但是这也只是一个假说，而且也有研究说只有在特定情况（Learning rate较小等）下才能观察到大乐透假设的现象

## [Knowledge Distillation（知识蒸馏）](https://blog.csdn.net/weixin_44022810/article/details/127533192?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172301492616800188559129%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172301492616800188559129&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-127533192-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=knowledge%20distillation&spm=1018.2226.3001.4187)
![输入图片说明](/imgs/2024-08-07/xJuEsJ9aWqeNGx9U.png)
先训练好一个较大的模型，让小的模型逼近这个大模型（交叉熵最小），小模型可以从中获得训练资料的隐藏信息（比如数字辨识中，“1”和“7”有些相似），这样得到的小模型的训练效果往往比直接训练小模型的效果要好

teacher network 不止可以用一个大模型，还可以用多个大模型
![输入图片说明](/imgs/2024-08-07/4In1wtmfZINiVDc7.png)

softmax的小变形
![输入图片说明](/imgs/2024-08-07/qT72yoQZzeFbOXje.png)
T是要人为设定的
teacher network经过这样的变形后，结果分数的排名是不会变的，但是分数之间的分布会更平均，student network可以学习得更好

## Parameter Quantization（模型量化）
![输入图片说明](/imgs/2024-08-07/AWHlGQy9pPYgq6IO.png)

### binary weights(二元权重）
![输入图片说明](/imgs/2024-08-07/BxYZoeJOic3AFBew.png)
每个节点只用1或-1来表示，即只用+1,-1表示一个Weight。

> -   第一步我们先计算出和蓝色节点最接近的二元节点，并计算出其梯度方向（红色剪头）
> -   第二步，蓝色节点的更新方向则是按照红色箭头方向更新，而不是按照他自身的梯度方向更新。
> -   最后在满足一定条件后(例如训练之最大次数),用离得最近的Binary Weight（二元权重）作为结果即可。
## Architecture Design（架构设计）

第一步，先不考虑channel之间的联系，每个filter 对应一个channel，得到一个feature map
![输入图片说明](/imgs/2024-08-07/KfcfQiL7RlxJfKuX.png)

第二步，考虑不同channel 之间的联系
强制filter大小是1 X 1的，并且filter 的channel 数量等于输入数据的channel 数量，然后按照正常的CNN做法得到feature map
![输入图片说明](/imgs/2024-08-07/67kADN8e26nRQ48f.png)
![输入图片说明](/imgs/2024-08-07/3i6U9kbcz2O8QHnx.png)

### Low rank approximation
![输入图片说明](/imgs/2024-08-07/7wBeOWAjkvpPlFb3.png)
对参数会有一些限制

> 低秩之所以叫低秩，是因为原来的矩阵的秩最大可能是min(M,N),而新增一层后可以看到矩阵U和V的秩都是小于等于K的，我们都知道有矩阵秩运算公式rank(AB)≤min(rank(A),rank(B))，所以相乘之后的矩阵的秩一定是小于等于K 。

![输入图片说明](/imgs/2024-08-07/LzsrdDZVJD0vAMtP.png)

## Dynamic Computation
希望模型可以动态地调整来适应不同的运算资源环境/问题的难易
![输入图片说明](/imgs/2024-08-07/nbFTiKbhqmsfeMSR.png)
存储空间有限

1.模型动态调整网络的深度
![输入图片说明](/imgs/2024-08-07/78oCiqayqwPgKKOG.png)
extra layer根据hidden layer的输出决定分类的结果
模型根据目前的电量来决定从哪里输出
训练时minimize L

2.模型动态调整网络的宽度
![输入图片说明](/imgs/2024-08-07/rW1pPs2WPSVcj4Y3.png)
都是相同的网络只是每层使用的神经元数量不同

![输入图片说明](/imgs/2024-08-07/W3TCxIgKOqFbrcLD.png)

# Life Long Learning

在不同的任务上发生了遗忘！（θ1和θ2是在不同的任务中是一样的）
![输入图片说明](/imgs/2024-08-07/X2QGlEjhVX7yymZD.png)

## Selective Synaptic Plasticity
![输入图片说明](/imgs/2024-08-07/02MD53YDiVCClwUe.png)
θ 的上标b代表过去任务的序号，下标i代表第几个参数
![输入图片说明](/imgs/2024-08-07/IKy4814xgrJzHZ9x.png)
bi需要人为设定，可以通过一些方法算出来，这也是lifelong learning的难点所在

如何决定bi的大小呢？
![输入图片说明](/imgs/2024-08-07/dVJSlcGfqniOZ5i6.png)
也就是说，在训练任务2时，最好只在θ1的方向上移动，不要在θ2的方向上移动

![输入图片说明](/imgs/2024-08-07/qlMqdnaHLnpvcA8H.png)
实做
![输入图片说明](/imgs/2024-08-07/gK9ZttjssO2xmOM6.png)

求bi的方法
![输入图片说明](/imgs/2024-08-07/f2sLuZhWxuDsJqjw.png)

## Gradient Episodic Memory(GEM)
![输入图片说明](/imgs/2024-08-07/iOJu0srRSphGteNy.png)
存储了少量过去的资料，修改gradient的方向

## Additional Neural Resource Allocation
### Progressive Neural Networks
在训练新的任务时，保留之前的参数，搭建新的network，将旧的任务的hidden layer的输出作为输入的一部分，训练新的network
![输入图片说明](/imgs/2024-08-07/sv9NYUbqDM8x8O8c.png)
但是这种方法会占很多memory，不是一个好的方法；当任务量不是很多时，该方法可以派上用场

### PackNet
一开始就创造比较多的神经元，每个任务只使用一部分
![输入图片说明](/imgs/2024-08-07/DR32XJFIZMBluuPX.png)

PackNet 可以和 Progressive Neural Network 结合起来，叫作CPG
![输入图片说明](/imgs/2024-08-07/wE7XZjJmRBDp4tp6.png)
既可以增加新的参数，有只保留部分的参数拿来做训练

### Memory Replay
用generator产生过去的资料
![输入图片说明](/imgs/2024-08-07/9MTL9Wwd8AJcuqpe.png)
如果generator所占的空间少于训练资料所占的空间，也许就是有效的方法

对于分类问题，要求不同任务的分的类别数量要相同
如果不同，可以用下面的做法
![输入图片说明](/imgs/2024-08-07/gWtCNmbp5D7h6aHU.png)

## Curriculum Learning
如果调换不同任务的学习顺序，会有非常不一样的结果
任务一是辨识杂讯的图片，任务二是辨识没有杂讯的图片
![输入图片说明](/imgs/2024-08-07/gPnuVE3fc2WC2IkI.png)
下面的情况“”（先任务二再任务一）就没有遗忘的情况

# Meta learning（元学习）

> 元学习Meta Learning，含义为学会学习，即learn to learn，带着对人类的“学习能力”的期望诞生的。Meta Learning希望使得模型获取一种 **“学会学习”** 的能力，使其可以在获取已有“知识”的基础上快速学习新的任务。

![输入图片说明](/imgs/2024-08-07/RLO17JQTyzTIiFGO.png)
输出可以应用于新的任务

## 元学习演算法
类似于机器学习
### step 1
![输入图片说明](/imgs/2024-08-07/Zk61m1KkYNBhYPyj.png)

### step 2
元学习需要很多训练任务，每个任务中都有训练资料和测试资料，下图是举例要训练一个二元分类器
![输入图片说明](/imgs/2024-08-07/dJ8ShXYOdPNz2qi4.png)

如何判断一个learning algorithm（F）好不好呢？
把 F 的输出 f 用在训练资料（labeled）上，对得到的结果l进行分析，在此处以二元分类为例，f 的输出结果与正确答案的交叉熵加起来得到 l ，l 越小说明 f 越好，f 越好说明 F 越好，反之越差
![输入图片说明](/imgs/2024-08-07/IS7lwqNh9k2Ktq5Z.png)
因为元学习有多个任务，多个任务都要考虑到
![输入图片说明](/imgs/2024-08-07/rfC98pMy3dNL6mHs.png)

———————————————————————————————————————————
![输入图片说明](/imgs/2024-08-07/tx5e52PNeYu9ec2O.png)

### step 3
![输入图片说明](/imgs/2024-08-07/19Rkv9WAe63AqRQS.png)
L能不能微分取决于对应的φ是什么，如果φ是连续的可能就可以微分（比如learning rate），如果是离散的就不能（比如用几层network架构就是离散的）

### summary
![输入图片说明](/imgs/2024-08-07/iu2gJk1AGIwfSCu2.png)

## ML  VS  Meta
![输入图片说明](/imgs/2024-08-07/EEcieVlgazbvhwUN.png)
![输入图片说明](/imgs/2024-08-07/06RrDTmeJ4mlcpYH.png)
![输入图片说明](/imgs/2024-08-07/rPrscr3Hfsle2htY.png)

![输入图片说明](/imgs/2024-08-07/wY1MvO21muOM0wlM.png)
一次within-task training + 一次within-task testing 叫做 episode

![输入图片说明](/imgs/2024-08-07/qoQ0ut5xNXQTXnDR.png)

![输入图片说明](/imgs/2024-08-07/loJzEcEgR111hoaV.png)

——————————————————————————————
相同点：
![输入图片说明](/imgs/2024-08-07/YpNAl8AvjA9UUKuU.png)
development set 用来选择模型/决定network架构

## what is learnable

元学习中，初始化的参数（θ0）是可以训练的
![输入图片说明](/imgs/2024-08-08/sBqYavrtpsjTHCj8.png)
使用Model-Agnostic Meta-Learning（MAML）来学习初始化

learning rate 也是可以学出来的
![输入图片说明](/imgs/2024-08-08/zrnyauWxjJYeyZBh.png)
可以训练optimizer

还可以训练 network 架构
![输入图片说明](/imgs/2024-08-08/sIZ0ardy6jb3Fp7m.png)
![输入图片说明](/imgs/2024-08-08/Z56tiwxigHF3bbXy.png)
![输入图片说明](/imgs/2024-08-08/5OxUcneTOQTzmqA4.png)
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTU5NzgwOTE3NF19
-->